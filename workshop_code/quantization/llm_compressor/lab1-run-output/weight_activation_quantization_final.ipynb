{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7854d876-3cd1-4a18-bf9c-4c947166fd88",
   "metadata": {},
   "source": [
    "# Quantization of `granite-3.3-2b-instruct` model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b258eb-3223-4594-860e-daae9d3a5c1d",
   "metadata": {},
   "source": [
    "Recall that our overall solution uses the quantized version of the model `granite-3.3-2b-instruct`. In this lab, we will be taking in the base model `granite-3.3-2b-instruct` and quantizing it to `W4A16` - which is fixed-point integer (INT) quantization scheme for weights and floating‑point for activations - to provide both memory savings (weight - INT4) and inference acceleration (activations - BF16) with `vLLM`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7800f926-dc4c-42a1-84a7-03be28d7463f",
   "metadata": {},
   "source": [
    "**Note**: `W4A16` computation is supported on Nvidia GPUs with compute capability > 7.5 (Turing, Ampere, Ada Lovelace, Hopper).\n",
    "\n",
    "**Note**: The steps here will take around 20-30 minutes, depending on the connectivity. The most time consuming steps are the installation of llmcompressor (up to 5 mins) and the quantization step (which can take more anywhere between 10-15 mins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef99081-3a8b-486c-9882-deb387c83850",
   "metadata": {},
   "source": [
    "## Setting up llm-compressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53691745",
   "metadata": {},
   "source": [
    "Installing `llmcompressor` may take a minute, depending on the bandwith available. Do note the versions of `transformer` library we would be using. There is a known issue (*torch.fx.proxy.TraceError: symbolically traced variables cannot be used as inputs to control flow*) with the usage of the latest transformer library (version `4.53.2` as of July 17, 2025) in combination with the latest version of llmcompressor (version `0.6.0`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5037b244-10f5-4aac-981a-3a07864e0e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "vllm 0.10.0 requires transformers>=4.53.2, but you have transformers 4.52.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q llmcompressor==0.6.0 transformers==4.52.2 boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c484403-9fd6-489d-9912-8e7153c97749",
   "metadata": {},
   "source": [
    "Let's make sure we have installed the right versions installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2e9e9b1-1e04-4c1c-be37-617c489b2678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llmcompressor                     0.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep llmcompressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e405cb5c-843d-4f12-8fbc-fa1e8db4f7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers                      4.52.2\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd24bf14-c77b-4f07-851d-d70cc61646eb",
   "metadata": {},
   "source": [
    "## Let' start with the quantization of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55327b5b-b309-4c23-a245-70d78d0955fc",
   "metadata": {},
   "source": [
    "There are 6 steps:\n",
    "1. Loading the model\n",
    "2. Choosing the quantization scheme and method\n",
    "3. Preparing the calibration data\n",
    "4. Applying quantization\n",
    "5. Saving the model\n",
    "6. Evaluation of accuracy in vLLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aad553f-1f6f-4583-b280-6205930debe8",
   "metadata": {},
   "source": [
    "### Loading the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338d3096-978c-415a-9529-45f8b455e577",
   "metadata": {},
   "source": [
    "First, let's download the model from local S3 and then load the model using AutoModelForCausalLM for handling quantized saving and loading. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8e1df99-46b5-45a6-98f5-cea3adae88ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from boto3 import client\n",
    "\n",
    "def download_model_from_s3(s3_path, local_model_dir):\n",
    "    print('Starting download of model from S3')\n",
    "    \n",
    "    # Get S3 credentials from environment\n",
    "    s3_endpoint_url = os.environ[\"AWS_S3_ENDPOINT\"]\n",
    "    s3_access_key = os.environ[\"AWS_ACCESS_KEY_ID\"]\n",
    "    s3_secret_key = os.environ[\"AWS_SECRET_ACCESS_KEY\"]\n",
    "    s3_bucket_name = os.environ[\"AWS_S3_BUCKET\"]\n",
    "\n",
    "    print(f'Downloading model from bucket {s3_bucket_name} '\n",
    "          f'path {s3_path} from S3 storage at {s3_endpoint_url}')\n",
    "    print(f'Target local directory: {local_model_dir}')\n",
    "\n",
    "    s3_client = client(\n",
    "        's3', endpoint_url=s3_endpoint_url, aws_access_key_id=s3_access_key,\n",
    "        aws_secret_access_key=s3_secret_key, verify=False\n",
    "    )\n",
    "\n",
    "    os.makedirs(local_model_dir, exist_ok=True)\n",
    "\n",
    "    print(f'Listing objects with prefix: {s3_path}')\n",
    "    paginator = s3_client.get_paginator('list_objects_v2')\n",
    "    pages = paginator.paginate(Bucket=s3_bucket_name, Prefix=s3_path)\n",
    "\n",
    "    downloaded_files = []\n",
    "    total_objects = 0\n",
    "    \n",
    "    for page in pages:\n",
    "        if 'Contents' in page:\n",
    "            for obj in page['Contents']:\n",
    "                total_objects += 1\n",
    "                s3_key = obj['Key']\n",
    "                print(f'Found S3 object: {s3_key}')\n",
    "                \n",
    "                # Skip if it's just a directory marker\n",
    "                if s3_key.endswith('/'):\n",
    "                    print(f'Skipping directory marker: {s3_key}')\n",
    "                    continue\n",
    "                \n",
    "                relative_path = s3_key[len(s3_path):].lstrip('/')\n",
    "                local_file_path = os.path.join(local_model_dir, relative_path)\n",
    "                \n",
    "                print(f'S3 key: {s3_key}')\n",
    "                print(f'Local file path: {local_file_path}')\n",
    "                \n",
    "                local_dir = os.path.dirname(local_file_path)\n",
    "                if local_dir:\n",
    "                    os.makedirs(local_dir, exist_ok=True)\n",
    "                    print(f'Created directory: {local_dir}')\n",
    "                \n",
    "                try:\n",
    "                    s3_client.download_file(s3_bucket_name, s3_key, local_file_path)\n",
    "                    downloaded_files.append(local_file_path)\n",
    "                    print(f'Successfully downloaded {s3_key} to {local_file_path}')\n",
    "                except Exception as e:\n",
    "                    print(f'Error downloading {s3_key}: {e}')\n",
    "                    raise\n",
    "\n",
    "    print(f'Total objects found: {total_objects}')\n",
    "    print(f'Files downloaded: {len(downloaded_files)}')\n",
    "    \n",
    "    config_path = os.path.join(local_model_dir, 'config.json')\n",
    "    if os.path.exists(config_path):\n",
    "        print(f'Verified: config.json found at {config_path}')\n",
    "    else:\n",
    "        print(f'Warning: config.json not found at {config_path}')\n",
    "    \n",
    "    print('Finished downloading model from S3')\n",
    "    return local_model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1141b43a-5483-41e6-b33d-34ceb891e90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download of model from S3\n",
      "Downloading model from bucket models path ibm-granite/granite-3.3-2b-instruct/ from S3 storage at http://minio-service.minio.svc.cluster.local:9000\n",
      "Target local directory: /opt/app-root/src/granite-3.3-2b-instruct\n",
      "Listing objects with prefix: ibm-granite/granite-3.3-2b-instruct/\n",
      "Found S3 object: ibm-granite/granite-3.3-2b-instruct/.gitattributes\n",
      "S3 key: ibm-granite/granite-3.3-2b-instruct/.gitattributes\n",
      "Local file path: /opt/app-root/src/granite-3.3-2b-instruct/.gitattributes\n",
      "Created directory: /opt/app-root/src/granite-3.3-2b-instruct\n",
      "Successfully downloaded ibm-granite/granite-3.3-2b-instruct/.gitattributes to /opt/app-root/src/granite-3.3-2b-instruct/.gitattributes\n",
      "Found S3 object: ibm-granite/granite-3.3-2b-instruct/README.md\n",
      "S3 key: ibm-granite/granite-3.3-2b-instruct/README.md\n",
      "Local file path: /opt/app-root/src/granite-3.3-2b-instruct/README.md\n",
      "Created directory: /opt/app-root/src/granite-3.3-2b-instruct\n",
      "Successfully downloaded ibm-granite/granite-3.3-2b-instruct/README.md to /opt/app-root/src/granite-3.3-2b-instruct/README.md\n",
      "Found S3 object: ibm-granite/granite-3.3-2b-instruct/added_tokens.json\n",
      "S3 key: ibm-granite/granite-3.3-2b-instruct/added_tokens.json\n",
      "Local file path: /opt/app-root/src/granite-3.3-2b-instruct/added_tokens.json\n",
      "Created directory: /opt/app-root/src/granite-3.3-2b-instruct\n",
      "Successfully downloaded ibm-granite/granite-3.3-2b-instruct/added_tokens.json to /opt/app-root/src/granite-3.3-2b-instruct/added_tokens.json\n",
      "Found S3 object: ibm-granite/granite-3.3-2b-instruct/config.json\n",
      "S3 key: ibm-granite/granite-3.3-2b-instruct/config.json\n",
      "Local file path: /opt/app-root/src/granite-3.3-2b-instruct/config.json\n",
      "Created directory: /opt/app-root/src/granite-3.3-2b-instruct\n",
      "Successfully downloaded ibm-granite/granite-3.3-2b-instruct/config.json to /opt/app-root/src/granite-3.3-2b-instruct/config.json\n",
      "Found S3 object: ibm-granite/granite-3.3-2b-instruct/generation_config.json\n",
      "S3 key: ibm-granite/granite-3.3-2b-instruct/generation_config.json\n",
      "Local file path: /opt/app-root/src/granite-3.3-2b-instruct/generation_config.json\n",
      "Created directory: /opt/app-root/src/granite-3.3-2b-instruct\n",
      "Successfully downloaded ibm-granite/granite-3.3-2b-instruct/generation_config.json to /opt/app-root/src/granite-3.3-2b-instruct/generation_config.json\n",
      "Found S3 object: ibm-granite/granite-3.3-2b-instruct/merges.txt\n",
      "S3 key: ibm-granite/granite-3.3-2b-instruct/merges.txt\n",
      "Local file path: /opt/app-root/src/granite-3.3-2b-instruct/merges.txt\n",
      "Created directory: /opt/app-root/src/granite-3.3-2b-instruct\n",
      "Successfully downloaded ibm-granite/granite-3.3-2b-instruct/merges.txt to /opt/app-root/src/granite-3.3-2b-instruct/merges.txt\n",
      "Found S3 object: ibm-granite/granite-3.3-2b-instruct/model-00001-of-00002.safetensors\n",
      "S3 key: ibm-granite/granite-3.3-2b-instruct/model-00001-of-00002.safetensors\n",
      "Local file path: /opt/app-root/src/granite-3.3-2b-instruct/model-00001-of-00002.safetensors\n",
      "Created directory: /opt/app-root/src/granite-3.3-2b-instruct\n",
      "Successfully downloaded ibm-granite/granite-3.3-2b-instruct/model-00001-of-00002.safetensors to /opt/app-root/src/granite-3.3-2b-instruct/model-00001-of-00002.safetensors\n",
      "Found S3 object: ibm-granite/granite-3.3-2b-instruct/model-00002-of-00002.safetensors\n",
      "S3 key: ibm-granite/granite-3.3-2b-instruct/model-00002-of-00002.safetensors\n",
      "Local file path: /opt/app-root/src/granite-3.3-2b-instruct/model-00002-of-00002.safetensors\n",
      "Created directory: /opt/app-root/src/granite-3.3-2b-instruct\n",
      "Successfully downloaded ibm-granite/granite-3.3-2b-instruct/model-00002-of-00002.safetensors to /opt/app-root/src/granite-3.3-2b-instruct/model-00002-of-00002.safetensors\n",
      "Found S3 object: ibm-granite/granite-3.3-2b-instruct/model.safetensors.index.json\n",
      "S3 key: ibm-granite/granite-3.3-2b-instruct/model.safetensors.index.json\n",
      "Local file path: /opt/app-root/src/granite-3.3-2b-instruct/model.safetensors.index.json\n",
      "Created directory: /opt/app-root/src/granite-3.3-2b-instruct\n",
      "Successfully downloaded ibm-granite/granite-3.3-2b-instruct/model.safetensors.index.json to /opt/app-root/src/granite-3.3-2b-instruct/model.safetensors.index.json\n",
      "Found S3 object: ibm-granite/granite-3.3-2b-instruct/special_tokens_map.json\n",
      "S3 key: ibm-granite/granite-3.3-2b-instruct/special_tokens_map.json\n",
      "Local file path: /opt/app-root/src/granite-3.3-2b-instruct/special_tokens_map.json\n",
      "Created directory: /opt/app-root/src/granite-3.3-2b-instruct\n",
      "Successfully downloaded ibm-granite/granite-3.3-2b-instruct/special_tokens_map.json to /opt/app-root/src/granite-3.3-2b-instruct/special_tokens_map.json\n",
      "Found S3 object: ibm-granite/granite-3.3-2b-instruct/tokenizer.json\n",
      "S3 key: ibm-granite/granite-3.3-2b-instruct/tokenizer.json\n",
      "Local file path: /opt/app-root/src/granite-3.3-2b-instruct/tokenizer.json\n",
      "Created directory: /opt/app-root/src/granite-3.3-2b-instruct\n",
      "Successfully downloaded ibm-granite/granite-3.3-2b-instruct/tokenizer.json to /opt/app-root/src/granite-3.3-2b-instruct/tokenizer.json\n",
      "Found S3 object: ibm-granite/granite-3.3-2b-instruct/tokenizer_config.json\n",
      "S3 key: ibm-granite/granite-3.3-2b-instruct/tokenizer_config.json\n",
      "Local file path: /opt/app-root/src/granite-3.3-2b-instruct/tokenizer_config.json\n",
      "Created directory: /opt/app-root/src/granite-3.3-2b-instruct\n",
      "Successfully downloaded ibm-granite/granite-3.3-2b-instruct/tokenizer_config.json to /opt/app-root/src/granite-3.3-2b-instruct/tokenizer_config.json\n",
      "Found S3 object: ibm-granite/granite-3.3-2b-instruct/vocab.json\n",
      "S3 key: ibm-granite/granite-3.3-2b-instruct/vocab.json\n",
      "Local file path: /opt/app-root/src/granite-3.3-2b-instruct/vocab.json\n",
      "Created directory: /opt/app-root/src/granite-3.3-2b-instruct\n",
      "Successfully downloaded ibm-granite/granite-3.3-2b-instruct/vocab.json to /opt/app-root/src/granite-3.3-2b-instruct/vocab.json\n",
      "Total objects found: 13\n",
      "Files downloaded: 13\n",
      "Verified: config.json found at /opt/app-root/src/granite-3.3-2b-instruct/config.json\n",
      "Finished downloading model from S3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.44it/s]\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "BASE_MODEL_DIR = current_dir + \"/granite-3.3-2b-instruct\"\n",
    "S3_MODEL_PATH = \"ibm-granite/granite-3.3-2b-instruct/\"  \n",
    "\n",
    "model_path = download_model_from_s3(S3_MODEL_PATH, BASE_MODEL_DIR)\n",
    "\n",
    "# use the downloaded model path for tokenizer and model loading\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path, device_map=\"auto\", torch_dtype=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99299f19",
   "metadata": {},
   "source": [
    "Alternatively, the model can also be loaded from HuggingFace directly as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13ad8b7b-bb67-4d02-8cce-f80de7462f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# MODEL_ID = \"ibm-granite/granite-3.2-2b-instruct\"\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     MODEL_ID, device_map=\"auto\", torch_dtype=\"auto\",\n",
    "# )\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9742346d-f226-4462-871a-bf4008a04091",
   "metadata": {},
   "source": [
    "### Prepare calibration data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bdaadd-11b8-4627-be3d-3a1ffa4c9f88",
   "metadata": {},
   "source": [
    "Prepare the calibration data. When quantizing weigths of a model to int4 using GPTQ, we need some sample data to run the GPTQ algorithms. As a result, it is very important to use calibration data that closely matches the type of data used in our deployment. If you have fine-tuned a model, using a sample of your training data is a good idea.\n",
    "\n",
    "In our case, we are quantizing an Instruction tuned generic model, so we will use the ultrachat dataset. Some best practices include:\n",
    "- 512 samples is a good place to start (increase if accuracy drops). We are going to use 256 to speed up the process.\n",
    "- 2048 sequence length is a good place to start\n",
    "- Use the chat template or instrucion template that the model is trained with\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9c3b1c6-f408-4ec5-81a0-3e8ae8019070",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "NUM_CALIBRATION_SAMPLES = 512  # 1024\n",
    "DATASET_ID = \"neuralmagic/LLM_compression_calibration\"\n",
    "DATASET_SPLIT = \"train\"\n",
    "\n",
    "# Load dataset.\n",
    "ds = load_dataset(DATASET_ID, split=DATASET_SPLIT)\n",
    "ds = ds.shuffle(seed=42).select(range(NUM_CALIBRATION_SAMPLES))\n",
    "\n",
    "# Preprocess the data into the format the model is trained with.\n",
    "def preprocess(example):\n",
    "    return {\"text\": example[\"text\"]}\n",
    "ds = ds.map(preprocess)\n",
    "\n",
    "# Tokenize the data\n",
    "def tokenize(sample):\n",
    "    return tokenizer(\n",
    "        sample[\"text\"],\n",
    "        padding=False,\n",
    "        truncation=False,\n",
    "        add_special_tokens=True,\n",
    "    )\n",
    "ds = ds.map(tokenize, remove_columns=ds.column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2c889b-b827-4f8d-be34-2cc05bba48f1",
   "metadata": {},
   "source": [
    "With the dataset ready, we will now apply quantization.\n",
    "\n",
    "We first select the quantization algorithm. For W4A16, we want to:\n",
    "- Run SmoothQuant to make the activations easier to quantize\n",
    "- Quantize the weights to 4 bits with channelwise scales using GPTQ\n",
    "- Quantize the activations with dynamic per token strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1732929",
   "metadata": {},
   "source": [
    "**Note**: The quantization step takes a long time to complete due to the callibration requirements -- around 10 - 15 mins, depending on the GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9593615d-db1d-4b80-bd94-93868a45cd01",
   "metadata": {},
   "source": [
    "### Imports and definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da32a22-49bd-4480-b0e0-b0e052190ce0",
   "metadata": {},
   "source": [
    "**GPTQModifier**: Applies Gentle Quantization (GPTQ) for weight-only quantization.\n",
    "\n",
    "**SmoothQuantModifier**: Prepares model activations for smoother quantization by scaling internal activations and weights.\n",
    "\n",
    "**oneshot**: High-level API that applies your quantization recipe in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94c06b7f-aedb-4e06-98cd-16aed3abd046",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmcompressor.modifiers.quantization import GPTQModifier\n",
    "from llmcompressor.transformers import oneshot\n",
    "from llmcompressor.modifiers.smoothquant import SmoothQuantModifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556fec70-e27b-4bab-8e6b-f6268636c5d9",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12866bd2-e08a-419c-98c7-ced3e5853baa",
   "metadata": {},
   "source": [
    "Rationale\n",
    "- **DAMPENING_FRAC=0.1** gently prevents large Hessian-derived updates during quantization.\n",
    "- **OBSERVER=\"mse\"** measures quantization error by squared deviations, yielding well-rounded scales.\n",
    "- **GROUP_SIZE=128** determines group size for per-channel quantization; typical default usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a35cf573-dc89-4b5d-9414-aad06992c2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DAMPENING_FRAC = 0.1  # tapering adjustment to prevent extreme weight updates\n",
    "OBSERVER = \"mse\"  # denotes minmax - quantization layout based on mean‐squared‐error\n",
    "GROUP_SIZE = 128  # # per-channel grouping width for quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cb39b8-9fe3-4a7e-adba-9a03ec033344",
   "metadata": {},
   "source": [
    "### Layer Mappings & Ignoring Heads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422d76f3-61a5-474f-8b83-3005199b7122",
   "metadata": {},
   "source": [
    "Logic\n",
    "\n",
    "- **ignore=[\"lm_head\"]** skips quantization on the output layer to preserve final logits and maintain accuracy.\n",
    "- mappings link groups of linear projections (q, k, v, gating, up/down projections) with layernorm blocks—SmoothQuant uses these to shift and normalize activations across paired layers for better quant distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f4604b8-b311-428f-838e-a50bfc041b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore=[\"lm_head\"]\n",
    "mappings=[\n",
    "    [[\"re:.*q_proj\", \"re:.*k_proj\", \"re:.*v_proj\"], \"re:.*input_layernorm\"],\n",
    "    [[\"re:.*gate_proj\", \"re:.*up_proj\"], \"re:.*post_attention_layernorm\"],\n",
    "    [[\"re:.*down_proj\"], \"re:.*up_proj\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8918c2e-d6f1-4e31-aa56-57b5a7c3f1df",
   "metadata": {},
   "source": [
    "### Recipe Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b291ad00-d881-4efb-bba5-2b20d3b28a3d",
   "metadata": {},
   "source": [
    "**Workflow**\n",
    "\n",
    "- **SmoothQuantModifier**: Re-scales activations across paired layers before quantization to reduce outliers (smoothing_strength=0.7, high smoothing but not extreme).\n",
    "- **GPTQModifier**: Performs Weight-Only quantization (4-bit weights, 16-bit activations) on all Linear layers except those ignored, applying your dampening and observer settings. Scheme \"W4A16\" reduces model size while maintaining decent accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1abec4d4-a2a8-4e98-a813-b24e0aa8dc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe = [\n",
    "    SmoothQuantModifier(smoothing_strength=0.7, ignore=ignore, mappings=mappings),\n",
    "    GPTQModifier(\n",
    "        targets=[\"Linear\"],\n",
    "        ignore=ignore,\n",
    "        scheme=\"W4A16\",\n",
    "        dampening_frac=DAMPENING_FRAC,\n",
    "        observer=OBSERVER,\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8d0ba1-ca11-406b-b232-2d6edc17fcc7",
   "metadata": {},
   "source": [
    "### Quantize in One Shot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96817063-9eb7-4d4b-8ed9-19673f74967b",
   "metadata": {},
   "source": [
    "**How It Works**\n",
    "\n",
    "- Feeds dataset (calibration set) into your model to gather activation statistics.\n",
    "- Applies SmoothQuant rescaling followed by GPTQ quantization in a sequential per-layer manner.\n",
    "- **max_seq_length=8196** ensures large context coverage for calibration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62bf36ae-0774-4cee-8f99-c367c24303d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:15:44.561080+0000 | reset | INFO - Compression lifecycle reset\n",
      "2025-08-16T09:15:44.564115+0000 | from_modifiers | INFO - Creating recipe from modifiers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_948/180673739.py:1: DeprecationWarning: `from llmcompressor.transformers import oneshot` is deprecated, please use `from llmcompressor import oneshot`.\n",
      "  oneshot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:15:45.933448+0000 | initialize | INFO - Compression lifecycle initialized for 1 modifiers\n",
      "2025-08-16T09:15:45.934151+0000 | IndependentPipeline | INFO - Inferred `SequentialPipeline` for `SmoothQuantModifier`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing cache: 100%|██████████| 512/512 [00:00<00:00, 1501.20it/s]\n",
      "(1/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 283.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:15:50.352219+0000 | _apply_smoothing | INFO - Smoothing with model.layers.0.input_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:15:50.400204+0000 | _apply_smoothing | INFO - Smoothing with model.layers.0.post_attention_layernorm\n",
      "2025-08-16T09:15:50.402220+0000 | _apply_smoothing | INFO - Smoothing with model.layers.0.mlp.up_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(1/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 355.18it/s]\n",
      "(2/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 473.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:15:53.045000+0000 | _apply_smoothing | INFO - Smoothing with model.layers.1.input_layernorm\n",
      "2025-08-16T09:15:53.046173+0000 | _apply_smoothing | INFO - Smoothing with model.layers.1.post_attention_layernorm\n",
      "2025-08-16T09:15:53.047534+0000 | _apply_smoothing | INFO - Smoothing with model.layers.1.mlp.up_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(2/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 469.40it/s]\n",
      "(3/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 472.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:15:55.250345+0000 | _apply_smoothing | INFO - Smoothing with model.layers.2.input_layernorm\n",
      "2025-08-16T09:15:55.251621+0000 | _apply_smoothing | INFO - Smoothing with model.layers.2.post_attention_layernorm\n",
      "2025-08-16T09:15:55.252929+0000 | _apply_smoothing | INFO - Smoothing with model.layers.2.mlp.up_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(3/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 474.04it/s]\n",
      "(4/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 472.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:15:57.460846+0000 | _apply_smoothing | INFO - Smoothing with model.layers.3.input_layernorm\n",
      "2025-08-16T09:15:57.462022+0000 | _apply_smoothing | INFO - Smoothing with model.layers.3.post_attention_layernorm\n",
      "2025-08-16T09:15:57.463400+0000 | _apply_smoothing | INFO - Smoothing with model.layers.3.mlp.up_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(4/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 471.48it/s]\n",
      "(5/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 471.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:15:59.662461+0000 | _apply_smoothing | INFO - Smoothing with model.layers.4.input_layernorm\n",
      "2025-08-16T09:15:59.663684+0000 | _apply_smoothing | INFO - Smoothing with model.layers.4.post_attention_layernorm\n",
      "2025-08-16T09:15:59.665042+0000 | _apply_smoothing | INFO - Smoothing with model.layers.4.mlp.up_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(5/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 474.05it/s]\n",
      "(6/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 469.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:16:01.861968+0000 | _apply_smoothing | INFO - Smoothing with model.layers.5.input_layernorm\n",
      "2025-08-16T09:16:01.863318+0000 | _apply_smoothing | INFO - Smoothing with model.layers.5.post_attention_layernorm\n",
      "2025-08-16T09:16:01.864670+0000 | _apply_smoothing | INFO - Smoothing with model.layers.5.mlp.up_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(6/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 473.36it/s]\n",
      "(7/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 470.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:16:04.063151+0000 | _apply_smoothing | INFO - Smoothing with model.layers.6.input_layernorm\n",
      "2025-08-16T09:16:04.064236+0000 | _apply_smoothing | INFO - Smoothing with model.layers.6.post_attention_layernorm\n",
      "2025-08-16T09:16:04.065615+0000 | _apply_smoothing | INFO - Smoothing with model.layers.6.mlp.up_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(7/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 473.92it/s]\n",
      "(8/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 469.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:16:06.262265+0000 | _apply_smoothing | INFO - Smoothing with model.layers.7.input_layernorm\n",
      "2025-08-16T09:16:06.263296+0000 | _apply_smoothing | INFO - Smoothing with model.layers.7.post_attention_layernorm\n",
      "2025-08-16T09:16:06.264622+0000 | _apply_smoothing | INFO - Smoothing with model.layers.7.mlp.up_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(8/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 476.75it/s]\n",
      "(9/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 469.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:16:08.457422+0000 | _apply_smoothing | INFO - Smoothing with model.layers.8.input_layernorm\n",
      "2025-08-16T09:16:08.458720+0000 | _apply_smoothing | INFO - Smoothing with model.layers.8.post_attention_layernorm\n",
      "2025-08-16T09:16:08.460111+0000 | _apply_smoothing | INFO - Smoothing with model.layers.8.mlp.up_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(9/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 475.04it/s]\n",
      "(10/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 471.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:16:10.650769+0000 | _apply_smoothing | INFO - Smoothing with model.layers.9.input_layernorm\n",
      "2025-08-16T09:16:10.651996+0000 | _apply_smoothing | INFO - Smoothing with model.layers.9.post_attention_layernorm\n",
      "2025-08-16T09:16:10.653310+0000 | _apply_smoothing | INFO - Smoothing with model.layers.9.mlp.up_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(10/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 472.45it/s]\n",
      "(11/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 471.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:16:12.849016+0000 | _apply_smoothing | INFO - Smoothing with model.layers.10.input_layernorm\n",
      "2025-08-16T09:16:12.850135+0000 | _apply_smoothing | INFO - Smoothing with model.layers.10.post_attention_layernorm\n",
      "2025-08-16T09:16:12.851434+0000 | _apply_smoothing | INFO - Smoothing with model.layers.10.mlp.up_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(11/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 474.63it/s]\n",
      "(12/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 474.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:16:15.037823+0000 | _apply_smoothing | INFO - Smoothing with model.layers.11.input_layernorm\n",
      "2025-08-16T09:16:15.039108+0000 | _apply_smoothing | INFO - Smoothing with model.layers.11.post_attention_layernorm\n",
      "2025-08-16T09:16:15.040495+0000 | _apply_smoothing | INFO - Smoothing with model.layers.11.mlp.up_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(12/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 471.76it/s]\n",
      "(13/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 468.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:16:17.248231+0000 | _apply_smoothing | INFO - Smoothing with model.layers.12.input_layernorm\n",
      "2025-08-16T09:16:17.249620+0000 | _apply_smoothing | INFO - Smoothing with model.layers.12.post_attention_layernorm\n",
      "2025-08-16T09:16:17.250963+0000 | _apply_smoothing | INFO - Smoothing with model.layers.12.mlp.up_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(13/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 474.11it/s]\n",
      "(14/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 473.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:16:19.450255+0000 | _apply_smoothing | INFO - Smoothing with model.layers.13.input_layernorm\n",
      "2025-08-16T09:16:19.451321+0000 | _apply_smoothing | INFO - Smoothing with model.layers.13.post_attention_layernorm\n",
      "2025-08-16T09:16:19.452614+0000 | _apply_smoothing | INFO - Smoothing with model.layers.13.mlp.up_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(14/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 474.67it/s]\n",
      "(15/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 461.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:16:21.710554+0000 | _apply_smoothing | INFO - Smoothing with model.layers.14.input_layernorm\n",
      "2025-08-16T09:16:21.711753+0000 | _apply_smoothing | INFO - Smoothing with model.layers.14.post_attention_layernorm\n",
      "2025-08-16T09:16:21.713227+0000 | _apply_smoothing | INFO - Smoothing with model.layers.14.mlp.up_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(15/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 476.96it/s]\n",
      "(16/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 462.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:16:23.946279+0000 | _apply_smoothing | INFO - Smoothing with model.layers.15.input_layernorm\n",
      "2025-08-16T09:16:23.947703+0000 | _apply_smoothing | INFO - Smoothing with model.layers.15.post_attention_layernorm\n",
      "2025-08-16T09:16:23.949068+0000 | _apply_smoothing | INFO - Smoothing with model.layers.15.mlp.up_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(16/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 475.52it/s]\n",
      "(17/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 465.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:16:26.176759+0000 | _apply_smoothing | INFO - Smoothing with model.layers.16.input_layernorm\n",
      "2025-08-16T09:16:26.178015+0000 | _apply_smoothing | INFO - Smoothing with model.layers.16.post_attention_layernorm\n",
      "2025-08-16T09:16:26.179391+0000 | _apply_smoothing | INFO - Smoothing with model.layers.16.mlp.up_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(17/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 477.35it/s]\n",
      "(18/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 469.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:16:28.400208+0000 | _apply_smoothing | INFO - Smoothing with model.layers.17.input_layernorm\n",
      "2025-08-16T09:16:28.401563+0000 | _apply_smoothing | INFO - Smoothing with model.layers.17.post_attention_layernorm\n",
      "2025-08-16T09:16:28.402944+0000 | _apply_smoothing | INFO - Smoothing with model.layers.17.mlp.up_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(18/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 474.55it/s]\n",
      "(19/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 463.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:16:30.649543+0000 | _apply_smoothing | INFO - Smoothing with model.layers.18.input_layernorm\n",
      "2025-08-16T09:16:30.650997+0000 | _apply_smoothing | INFO - Smoothing with model.layers.18.post_attention_layernorm\n",
      "2025-08-16T09:16:30.652471+0000 | _apply_smoothing | INFO - Smoothing with model.layers.18.mlp.up_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(19/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 475.57it/s]\n",
      "(20/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 465.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:16:32.885470+0000 | _apply_smoothing | INFO - Smoothing with model.layers.19.input_layernorm\n",
      "2025-08-16T09:16:32.886541+0000 | _apply_smoothing | INFO - Smoothing with model.layers.19.post_attention_layernorm\n",
      "2025-08-16T09:16:32.887935+0000 | _apply_smoothing | INFO - Smoothing with model.layers.19.mlp.up_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(20/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 476.38it/s]\n",
      "(21/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 458.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:16:35.142315+0000 | _apply_smoothing | INFO - Smoothing with model.layers.20.input_layernorm\n",
      "2025-08-16T09:16:35.143549+0000 | _apply_smoothing | INFO - Smoothing with model.layers.20.post_attention_layernorm\n",
      "2025-08-16T09:16:35.144930+0000 | _apply_smoothing | INFO - Smoothing with model.layers.20.mlp.up_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(21/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 472.14it/s]\n",
      "(22/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 470.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:16:37.374262+0000 | _apply_smoothing | INFO - Smoothing with model.layers.21.input_layernorm\n",
      "2025-08-16T09:16:37.375677+0000 | _apply_smoothing | INFO - Smoothing with model.layers.21.post_attention_layernorm\n",
      "2025-08-16T09:16:37.377125+0000 | _apply_smoothing | INFO - Smoothing with model.layers.21.mlp.up_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(22/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 472.84it/s]\n",
      "(23/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 469.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:16:39.612846+0000 | _apply_smoothing | INFO - Smoothing with model.layers.22.input_layernorm\n",
      "2025-08-16T09:16:39.613965+0000 | _apply_smoothing | INFO - Smoothing with model.layers.22.post_attention_layernorm\n",
      "2025-08-16T09:16:39.615283+0000 | _apply_smoothing | INFO - Smoothing with model.layers.22.mlp.up_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(23/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 471.49it/s]\n",
      "(24/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 468.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:16:41.861126+0000 | _apply_smoothing | INFO - Smoothing with model.layers.23.input_layernorm\n",
      "2025-08-16T09:16:41.862369+0000 | _apply_smoothing | INFO - Smoothing with model.layers.23.post_attention_layernorm\n",
      "2025-08-16T09:16:41.863732+0000 | _apply_smoothing | INFO - Smoothing with model.layers.23.mlp.up_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(24/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 473.85it/s]\n",
      "(25/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 467.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:16:44.100733+0000 | _apply_smoothing | INFO - Smoothing with model.layers.24.input_layernorm\n",
      "2025-08-16T09:16:44.102112+0000 | _apply_smoothing | INFO - Smoothing with model.layers.24.post_attention_layernorm\n",
      "2025-08-16T09:16:44.103315+0000 | _apply_smoothing | INFO - Smoothing with model.layers.24.mlp.up_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(25/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 475.99it/s]\n",
      "(26/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 469.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:16:46.336915+0000 | _apply_smoothing | INFO - Smoothing with model.layers.25.input_layernorm\n",
      "2025-08-16T09:16:46.338228+0000 | _apply_smoothing | INFO - Smoothing with model.layers.25.post_attention_layernorm\n",
      "2025-08-16T09:16:46.339417+0000 | _apply_smoothing | INFO - Smoothing with model.layers.25.mlp.up_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(26/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 474.31it/s]\n",
      "(27/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 468.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:16:48.576246+0000 | _apply_smoothing | INFO - Smoothing with model.layers.26.input_layernorm\n",
      "2025-08-16T09:16:48.577727+0000 | _apply_smoothing | INFO - Smoothing with model.layers.26.post_attention_layernorm\n",
      "2025-08-16T09:16:48.579138+0000 | _apply_smoothing | INFO - Smoothing with model.layers.26.mlp.up_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(27/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 431.95it/s]\n",
      "(28/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 467.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:16:50.923264+0000 | _apply_smoothing | INFO - Smoothing with model.layers.27.input_layernorm\n",
      "2025-08-16T09:16:50.924544+0000 | _apply_smoothing | INFO - Smoothing with model.layers.27.post_attention_layernorm\n",
      "2025-08-16T09:16:50.925779+0000 | _apply_smoothing | INFO - Smoothing with model.layers.27.mlp.up_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(28/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 474.73it/s]\n",
      "(29/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 469.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:16:53.159316+0000 | _apply_smoothing | INFO - Smoothing with model.layers.28.input_layernorm\n",
      "2025-08-16T09:16:53.160392+0000 | _apply_smoothing | INFO - Smoothing with model.layers.28.post_attention_layernorm\n",
      "2025-08-16T09:16:53.161843+0000 | _apply_smoothing | INFO - Smoothing with model.layers.28.mlp.up_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(29/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 470.49it/s]\n",
      "(30/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 470.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:16:55.403942+0000 | _apply_smoothing | INFO - Smoothing with model.layers.29.input_layernorm\n",
      "2025-08-16T09:16:55.405137+0000 | _apply_smoothing | INFO - Smoothing with model.layers.29.post_attention_layernorm\n",
      "2025-08-16T09:16:55.406469+0000 | _apply_smoothing | INFO - Smoothing with model.layers.29.mlp.up_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(30/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 472.45it/s]\n",
      "(31/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 469.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:16:57.647297+0000 | _apply_smoothing | INFO - Smoothing with model.layers.30.input_layernorm\n",
      "2025-08-16T09:16:57.648744+0000 | _apply_smoothing | INFO - Smoothing with model.layers.30.post_attention_layernorm\n",
      "2025-08-16T09:16:57.650139+0000 | _apply_smoothing | INFO - Smoothing with model.layers.30.mlp.up_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(31/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 467.30it/s]\n",
      "(32/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 469.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:16:59.905626+0000 | _apply_smoothing | INFO - Smoothing with model.layers.31.input_layernorm\n",
      "2025-08-16T09:16:59.907094+0000 | _apply_smoothing | INFO - Smoothing with model.layers.31.post_attention_layernorm\n",
      "2025-08-16T09:16:59.908428+0000 | _apply_smoothing | INFO - Smoothing with model.layers.31.mlp.up_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(32/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 473.33it/s]\n",
      "(33/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 469.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:17:02.144471+0000 | _apply_smoothing | INFO - Smoothing with model.layers.32.input_layernorm\n",
      "2025-08-16T09:17:02.145525+0000 | _apply_smoothing | INFO - Smoothing with model.layers.32.post_attention_layernorm\n",
      "2025-08-16T09:17:02.146893+0000 | _apply_smoothing | INFO - Smoothing with model.layers.32.mlp.up_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(33/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 473.37it/s]\n",
      "(34/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 467.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:17:04.391271+0000 | _apply_smoothing | INFO - Smoothing with model.layers.33.input_layernorm\n",
      "2025-08-16T09:17:04.392705+0000 | _apply_smoothing | INFO - Smoothing with model.layers.33.post_attention_layernorm\n",
      "2025-08-16T09:17:04.394087+0000 | _apply_smoothing | INFO - Smoothing with model.layers.33.mlp.up_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(34/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 469.91it/s]\n",
      "(35/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 466.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:17:06.653328+0000 | _apply_smoothing | INFO - Smoothing with model.layers.34.input_layernorm\n",
      "2025-08-16T09:17:06.654813+0000 | _apply_smoothing | INFO - Smoothing with model.layers.34.post_attention_layernorm\n",
      "2025-08-16T09:17:06.656299+0000 | _apply_smoothing | INFO - Smoothing with model.layers.34.mlp.up_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(35/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 457.82it/s]\n",
      "(36/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 456.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:17:08.951607+0000 | _apply_smoothing | INFO - Smoothing with model.layers.35.input_layernorm\n",
      "2025-08-16T09:17:08.952877+0000 | _apply_smoothing | INFO - Smoothing with model.layers.35.post_attention_layernorm\n",
      "2025-08-16T09:17:08.954191+0000 | _apply_smoothing | INFO - Smoothing with model.layers.35.mlp.up_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(36/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 471.22it/s]\n",
      "(37/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 459.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:17:11.231150+0000 | _apply_smoothing | INFO - Smoothing with model.layers.36.input_layernorm\n",
      "2025-08-16T09:17:11.232583+0000 | _apply_smoothing | INFO - Smoothing with model.layers.36.post_attention_layernorm\n",
      "2025-08-16T09:17:11.233946+0000 | _apply_smoothing | INFO - Smoothing with model.layers.36.mlp.up_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(37/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 467.61it/s]\n",
      "(38/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 450.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:17:13.519312+0000 | _apply_smoothing | INFO - Smoothing with model.layers.37.input_layernorm\n",
      "2025-08-16T09:17:13.520406+0000 | _apply_smoothing | INFO - Smoothing with model.layers.37.post_attention_layernorm\n",
      "2025-08-16T09:17:13.521846+0000 | _apply_smoothing | INFO - Smoothing with model.layers.37.mlp.up_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(38/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 471.05it/s]\n",
      "(39/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 451.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:17:15.793193+0000 | _apply_smoothing | INFO - Smoothing with model.layers.38.input_layernorm\n",
      "2025-08-16T09:17:15.794547+0000 | _apply_smoothing | INFO - Smoothing with model.layers.38.post_attention_layernorm\n",
      "2025-08-16T09:17:15.796050+0000 | _apply_smoothing | INFO - Smoothing with model.layers.38.mlp.up_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(39/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 472.34it/s]\n",
      "(40/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 450.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:17:18.100023+0000 | _apply_smoothing | INFO - Smoothing with model.layers.39.input_layernorm\n",
      "2025-08-16T09:17:18.101378+0000 | _apply_smoothing | INFO - Smoothing with model.layers.39.post_attention_layernorm\n",
      "2025-08-16T09:17:18.102753+0000 | _apply_smoothing | INFO - Smoothing with model.layers.39.mlp.up_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(40/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 473.77it/s]\n",
      "(41/41): Calibrating: 100%|██████████| 512/512 [00:01<00:00, 298.52it/s]\n",
      "(41/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 298.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:17:22.786710+0000 | IndependentPipeline | INFO - Inferred `SequentialPipeline` for `GPTQModifier`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing cache: 100%|██████████| 512/512 [00:00<00:00, 2146.16it/s]\n",
      "(1/41): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 66.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:17:33.260223+0000 | compress_modules | INFO - Quantizing model.layers.0.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:17:34.504364+0000 | compress | METRIC - time 1.24s\n",
      "2025-08-16T09:17:34.505432+0000 | compress | METRIC - error 22241.08\n",
      "2025-08-16T09:17:34.506363+0000 | compress | METRIC - GPU 0 | usage: 25.48% | total memory: 24 GB\n",
      "2025-08-16T09:17:34.506816+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:17:34.507720+0000 | compress_modules | INFO - Quantizing model.layers.0.self_attn.k_proj using 512 samples\n",
      "2025-08-16T09:17:35.318101+0000 | compress | METRIC - time 0.81s\n",
      "2025-08-16T09:17:35.318818+0000 | compress | METRIC - error 7729.28\n",
      "2025-08-16T09:17:35.319623+0000 | compress | METRIC - GPU 0 | usage: 25.48% | total memory: 24 GB\n",
      "2025-08-16T09:17:35.320105+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:17:35.321097+0000 | compress_modules | INFO - Quantizing model.layers.0.self_attn.v_proj using 512 samples\n",
      "2025-08-16T09:17:36.109252+0000 | compress | METRIC - time 0.79s\n",
      "2025-08-16T09:17:36.110176+0000 | compress | METRIC - error 2619.62\n",
      "2025-08-16T09:17:36.110993+0000 | compress | METRIC - GPU 0 | usage: 25.48% | total memory: 24 GB\n",
      "2025-08-16T09:17:36.111453+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:17:36.112459+0000 | compress_modules | INFO - Quantizing model.layers.0.self_attn.o_proj using 512 samples\n",
      "2025-08-16T09:17:36.903025+0000 | compress | METRIC - time 0.79s\n",
      "2025-08-16T09:17:36.903877+0000 | compress | METRIC - error 945.63\n",
      "2025-08-16T09:17:36.904698+0000 | compress | METRIC - GPU 0 | usage: 25.48% | total memory: 24 GB\n",
      "2025-08-16T09:17:36.905361+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:17:36.906115+0000 | compress_modules | INFO - Quantizing model.layers.0.mlp.gate_proj using 512 samples\n",
      "2025-08-16T09:17:37.748214+0000 | compress | METRIC - time 0.84s\n",
      "2025-08-16T09:17:37.749148+0000 | compress | METRIC - error 10945.00\n",
      "2025-08-16T09:17:37.749966+0000 | compress | METRIC - GPU 0 | usage: 25.48% | total memory: 24 GB\n",
      "2025-08-16T09:17:37.750631+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:17:37.751410+0000 | compress_modules | INFO - Quantizing model.layers.0.mlp.up_proj using 512 samples\n",
      "2025-08-16T09:17:38.607111+0000 | compress | METRIC - time 0.86s\n",
      "2025-08-16T09:17:38.608039+0000 | compress | METRIC - error 194.01\n",
      "2025-08-16T09:17:38.608846+0000 | compress | METRIC - GPU 0 | usage: 25.48% | total memory: 24 GB\n",
      "2025-08-16T09:17:38.609295+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:17:38.610092+0000 | compress_modules | INFO - Quantizing model.layers.0.mlp.down_proj using 512 samples\n",
      "2025-08-16T09:17:41.987032+0000 | compress | METRIC - time 3.38s\n",
      "2025-08-16T09:17:41.988696+0000 | compress | METRIC - error 1310.62\n",
      "2025-08-16T09:17:41.989606+0000 | compress | METRIC - GPU 0 | usage: 25.48% | total memory: 24 GB\n",
      "2025-08-16T09:17:41.990129+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(1/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 398.27it/s]\n",
      "(2/41): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 66.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:17:51.019436+0000 | compress_modules | INFO - Quantizing model.layers.1.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:17:51.839451+0000 | compress | METRIC - time 0.82s\n",
      "2025-08-16T09:17:51.840305+0000 | compress | METRIC - error 13780.00\n",
      "2025-08-16T09:17:51.840999+0000 | compress | METRIC - GPU 0 | usage: 25.48% | total memory: 24 GB\n",
      "2025-08-16T09:17:51.841615+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:17:51.842303+0000 | compress_modules | INFO - Quantizing model.layers.1.self_attn.k_proj using 512 samples\n",
      "2025-08-16T09:17:52.705861+0000 | compress | METRIC - time 0.86s\n",
      "2025-08-16T09:17:52.706699+0000 | compress | METRIC - error 12779.66\n",
      "2025-08-16T09:17:52.707499+0000 | compress | METRIC - GPU 0 | usage: 25.48% | total memory: 24 GB\n",
      "2025-08-16T09:17:52.707968+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:17:52.708825+0000 | compress_modules | INFO - Quantizing model.layers.1.self_attn.v_proj using 512 samples\n",
      "2025-08-16T09:17:53.503001+0000 | compress | METRIC - time 0.79s\n",
      "2025-08-16T09:17:53.503856+0000 | compress | METRIC - error 1589.69\n",
      "2025-08-16T09:17:53.504655+0000 | compress | METRIC - GPU 0 | usage: 25.48% | total memory: 24 GB\n",
      "2025-08-16T09:17:53.505268+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:17:53.506001+0000 | compress_modules | INFO - Quantizing model.layers.1.self_attn.o_proj using 512 samples\n",
      "2025-08-16T09:17:54.303424+0000 | compress | METRIC - time 0.80s\n",
      "2025-08-16T09:17:54.304286+0000 | compress | METRIC - error 453.18\n",
      "2025-08-16T09:17:54.305038+0000 | compress | METRIC - GPU 0 | usage: 25.48% | total memory: 24 GB\n",
      "2025-08-16T09:17:54.305501+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:17:54.306247+0000 | compress_modules | INFO - Quantizing model.layers.1.mlp.gate_proj using 512 samples\n",
      "2025-08-16T09:17:55.133128+0000 | compress | METRIC - time 0.83s\n",
      "2025-08-16T09:17:55.134013+0000 | compress | METRIC - error 12537.10\n",
      "2025-08-16T09:17:55.134689+0000 | compress | METRIC - GPU 0 | usage: 25.48% | total memory: 24 GB\n",
      "2025-08-16T09:17:55.135108+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:17:55.135865+0000 | compress_modules | INFO - Quantizing model.layers.1.mlp.up_proj using 512 samples\n",
      "2025-08-16T09:17:55.959865+0000 | compress | METRIC - time 0.82s\n",
      "2025-08-16T09:17:55.960730+0000 | compress | METRIC - error 201.34\n",
      "2025-08-16T09:17:55.961368+0000 | compress | METRIC - GPU 0 | usage: 25.48% | total memory: 24 GB\n",
      "2025-08-16T09:17:55.961761+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:17:55.962505+0000 | compress_modules | INFO - Quantizing model.layers.1.mlp.down_proj using 512 samples\n",
      "2025-08-16T09:17:59.357743+0000 | compress | METRIC - time 3.39s\n",
      "2025-08-16T09:17:59.359138+0000 | compress | METRIC - error 721.17\n",
      "2025-08-16T09:17:59.359857+0000 | compress | METRIC - GPU 0 | usage: 25.48% | total memory: 24 GB\n",
      "2025-08-16T09:17:59.360383+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(2/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 471.88it/s]\n",
      "(3/41): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 66.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:18:08.116535+0000 | compress_modules | INFO - Quantizing model.layers.2.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:18:08.926492+0000 | compress | METRIC - time 0.81s\n",
      "2025-08-16T09:18:08.927464+0000 | compress | METRIC - error 16020.69\n",
      "2025-08-16T09:18:08.928162+0000 | compress | METRIC - GPU 0 | usage: 25.47% | total memory: 24 GB\n",
      "2025-08-16T09:18:08.928592+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:18:08.929292+0000 | compress_modules | INFO - Quantizing model.layers.2.self_attn.k_proj using 512 samples\n",
      "2025-08-16T09:18:09.710154+0000 | compress | METRIC - time 0.78s\n",
      "2025-08-16T09:18:09.711089+0000 | compress | METRIC - error 8008.41\n",
      "2025-08-16T09:18:09.711644+0000 | compress | METRIC - GPU 0 | usage: 25.47% | total memory: 24 GB\n",
      "2025-08-16T09:18:09.712059+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:18:09.712854+0000 | compress_modules | INFO - Quantizing model.layers.2.self_attn.v_proj using 512 samples\n",
      "2025-08-16T09:18:10.491865+0000 | compress | METRIC - time 0.78s\n",
      "2025-08-16T09:18:10.492901+0000 | compress | METRIC - error 1390.99\n",
      "2025-08-16T09:18:10.493498+0000 | compress | METRIC - GPU 0 | usage: 25.47% | total memory: 24 GB\n",
      "2025-08-16T09:18:10.494224+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:18:10.494849+0000 | compress_modules | INFO - Quantizing model.layers.2.self_attn.o_proj using 512 samples\n",
      "2025-08-16T09:18:11.282184+0000 | compress | METRIC - time 0.79s\n",
      "2025-08-16T09:18:11.283333+0000 | compress | METRIC - error 280.75\n",
      "2025-08-16T09:18:11.283926+0000 | compress | METRIC - GPU 0 | usage: 25.47% | total memory: 24 GB\n",
      "2025-08-16T09:18:11.284398+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:18:11.285232+0000 | compress_modules | INFO - Quantizing model.layers.2.mlp.gate_proj using 512 samples\n",
      "2025-08-16T09:18:12.103531+0000 | compress | METRIC - time 0.82s\n",
      "2025-08-16T09:18:12.104630+0000 | compress | METRIC - error 15133.87\n",
      "2025-08-16T09:18:12.105600+0000 | compress | METRIC - GPU 0 | usage: 25.47% | total memory: 24 GB\n",
      "2025-08-16T09:18:12.106317+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:18:12.107044+0000 | compress_modules | INFO - Quantizing model.layers.2.mlp.up_proj using 512 samples\n",
      "2025-08-16T09:18:12.923160+0000 | compress | METRIC - time 0.82s\n",
      "2025-08-16T09:18:12.924129+0000 | compress | METRIC - error 215.10\n",
      "2025-08-16T09:18:12.924726+0000 | compress | METRIC - GPU 0 | usage: 25.47% | total memory: 24 GB\n",
      "2025-08-16T09:18:12.925210+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:18:12.926397+0000 | compress_modules | INFO - Quantizing model.layers.2.mlp.down_proj using 512 samples\n",
      "2025-08-16T09:18:16.245562+0000 | compress | METRIC - time 3.32s\n",
      "2025-08-16T09:18:16.247078+0000 | compress | METRIC - error 669.91\n",
      "2025-08-16T09:18:16.247880+0000 | compress | METRIC - GPU 0 | usage: 25.47% | total memory: 24 GB\n",
      "2025-08-16T09:18:16.248353+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(3/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 472.91it/s]\n",
      "(4/41): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 67.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:18:24.981316+0000 | compress_modules | INFO - Quantizing model.layers.3.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:18:25.787536+0000 | compress | METRIC - time 0.81s\n",
      "2025-08-16T09:18:25.788628+0000 | compress | METRIC - error 21088.79\n",
      "2025-08-16T09:18:25.789534+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:18:25.790071+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:18:25.790992+0000 | compress_modules | INFO - Quantizing model.layers.3.self_attn.k_proj using 512 samples\n",
      "2025-08-16T09:18:26.571161+0000 | compress | METRIC - time 0.78s\n",
      "2025-08-16T09:18:26.572129+0000 | compress | METRIC - error 9300.08\n",
      "2025-08-16T09:18:26.573041+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:18:26.573497+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:18:26.574410+0000 | compress_modules | INFO - Quantizing model.layers.3.self_attn.v_proj using 512 samples\n",
      "2025-08-16T09:18:27.363596+0000 | compress | METRIC - time 0.79s\n",
      "2025-08-16T09:18:27.364581+0000 | compress | METRIC - error 1405.21\n",
      "2025-08-16T09:18:27.365435+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:18:27.365885+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:18:27.366730+0000 | compress_modules | INFO - Quantizing model.layers.3.self_attn.o_proj using 512 samples\n",
      "2025-08-16T09:18:28.180454+0000 | compress | METRIC - time 0.81s\n",
      "2025-08-16T09:18:28.181400+0000 | compress | METRIC - error 214.37\n",
      "2025-08-16T09:18:28.182222+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:18:28.182634+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:18:28.183467+0000 | compress_modules | INFO - Quantizing model.layers.3.mlp.gate_proj using 512 samples\n",
      "2025-08-16T09:18:29.020376+0000 | compress | METRIC - time 0.84s\n",
      "2025-08-16T09:18:29.021295+0000 | compress | METRIC - error 14221.08\n",
      "2025-08-16T09:18:29.022083+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:18:29.022518+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:18:29.023335+0000 | compress_modules | INFO - Quantizing model.layers.3.mlp.up_proj using 512 samples\n",
      "2025-08-16T09:18:29.853727+0000 | compress | METRIC - time 0.83s\n",
      "2025-08-16T09:18:29.854625+0000 | compress | METRIC - error 213.28\n",
      "2025-08-16T09:18:29.855448+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:18:29.855881+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:18:29.856721+0000 | compress_modules | INFO - Quantizing model.layers.3.mlp.down_proj using 512 samples\n",
      "2025-08-16T09:18:33.192859+0000 | compress | METRIC - time 3.34s\n",
      "2025-08-16T09:18:33.194439+0000 | compress | METRIC - error 1790.93\n",
      "2025-08-16T09:18:33.195332+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:18:33.195800+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(4/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 467.28it/s]\n",
      "(5/41): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 66.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:18:41.973126+0000 | compress_modules | INFO - Quantizing model.layers.4.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:18:42.796914+0000 | compress | METRIC - time 0.82s\n",
      "2025-08-16T09:18:42.797861+0000 | compress | METRIC - error 26743.89\n",
      "2025-08-16T09:18:42.798404+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:18:42.799033+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:18:42.799667+0000 | compress_modules | INFO - Quantizing model.layers.4.self_attn.k_proj using 512 samples\n",
      "2025-08-16T09:18:43.582834+0000 | compress | METRIC - time 0.78s\n",
      "2025-08-16T09:18:43.583837+0000 | compress | METRIC - error 12433.05\n",
      "2025-08-16T09:18:43.584574+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:18:43.585084+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:18:43.585761+0000 | compress_modules | INFO - Quantizing model.layers.4.self_attn.v_proj using 512 samples\n",
      "2025-08-16T09:18:44.371251+0000 | compress | METRIC - time 0.79s\n",
      "2025-08-16T09:18:44.372219+0000 | compress | METRIC - error 1844.94\n",
      "2025-08-16T09:18:44.372866+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:18:44.373240+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:18:44.373946+0000 | compress_modules | INFO - Quantizing model.layers.4.self_attn.o_proj using 512 samples\n",
      "2025-08-16T09:18:45.167667+0000 | compress | METRIC - time 0.79s\n",
      "2025-08-16T09:18:45.168645+0000 | compress | METRIC - error 201.30\n",
      "2025-08-16T09:18:45.169820+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:18:45.170342+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:18:45.171003+0000 | compress_modules | INFO - Quantizing model.layers.4.mlp.gate_proj using 512 samples\n",
      "2025-08-16T09:18:46.019826+0000 | compress | METRIC - time 0.85s\n",
      "2025-08-16T09:18:46.020939+0000 | compress | METRIC - error 14280.81\n",
      "2025-08-16T09:18:46.021524+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:18:46.021934+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:18:46.022581+0000 | compress_modules | INFO - Quantizing model.layers.4.mlp.up_proj using 512 samples\n",
      "2025-08-16T09:19:58.403709+0000 | compress | METRIC - time 3.39s\n",
      "2025-08-16T09:19:58.406422+0000 | compress | METRIC - error 1999101.88\n",
      "2025-08-16T09:19:58.407009+0000 | compress | METRIC - GPU 0 | usage: 25.54% | total memory: 24 GB\n",
      "2025-08-16T09:19:58.407373+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(9/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 470.73it/s]\n",
      "(10/41): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 66.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:20:07.202289+0000 | compress_modules | INFO - Quantizing model.layers.9.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:20:08.007489+0000 | compress | METRIC - time 0.80s\n",
      "2025-08-16T09:20:08.008422+0000 | compress | METRIC - error 35187.00\n",
      "2025-08-16T09:20:08.009168+0000 | compress | METRIC - GPU 0 | usage: 25.54% | total memory: 24 GB\n",
      "2025-08-16T09:20:08.009537+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:20:08.010251+0000 | compress_modules | INFO - Quantizing model.layers.9.self_attn.k_proj using 512 samples\n",
      "2025-08-16T09:20:08.782733+0000 | compress | METRIC - time 0.77s\n",
      "2025-08-16T09:20:08.783701+0000 | compress | METRIC - error 12908.41\n",
      "2025-08-16T09:20:08.784345+0000 | compress | METRIC - GPU 0 | usage: 25.54% | total memory: 24 GB\n",
      "2025-08-16T09:20:08.784721+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:20:08.785392+0000 | compress_modules | INFO - Quantizing model.layers.9.self_attn.v_proj using 512 samples\n",
      "2025-08-16T09:20:09.558123+0000 | compress | METRIC - time 0.77s\n",
      "2025-08-16T09:20:09.559100+0000 | compress | METRIC - error 1614.85\n",
      "2025-08-16T09:20:09.559834+0000 | compress | METRIC - GPU 0 | usage: 25.54% | total memory: 24 GB\n",
      "2025-08-16T09:20:09.560231+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:20:09.560906+0000 | compress_modules | INFO - Quantizing model.layers.9.self_attn.o_proj using 512 samples\n",
      "2025-08-16T09:20:10.344565+0000 | compress | METRIC - time 0.78s\n",
      "2025-08-16T09:20:10.345595+0000 | compress | METRIC - error 166.71\n",
      "2025-08-16T09:20:10.346489+0000 | compress | METRIC - GPU 0 | usage: 25.54% | total memory: 24 GB\n",
      "2025-08-16T09:20:10.346934+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:20:10.347583+0000 | compress_modules | INFO - Quantizing model.layers.9.mlp.gate_proj using 512 samples\n",
      "2025-08-16T09:20:11.179918+0000 | compress | METRIC - time 0.83s\n",
      "2025-08-16T09:20:11.180838+0000 | compress | METRIC - error 11602.35\n",
      "2025-08-16T09:20:11.181491+0000 | compress | METRIC - GPU 0 | usage: 25.54% | total memory: 24 GB\n",
      "2025-08-16T09:20:11.181920+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:20:11.182577+0000 | compress_modules | INFO - Quantizing model.layers.9.mlp.up_proj using 512 samples\n",
      "2025-08-16T09:20:12.000126+0000 | compress | METRIC - time 0.82s\n",
      "2025-08-16T09:20:12.001092+0000 | compress | METRIC - error 225.28\n",
      "2025-08-16T09:20:12.001590+0000 | compress | METRIC - GPU 0 | usage: 25.54% | total memory: 24 GB\n",
      "2025-08-16T09:20:12.002044+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:20:12.002874+0000 | compress_modules | INFO - Quantizing model.layers.9.mlp.down_proj using 512 samples\n",
      "2025-08-16T09:20:15.344519+0000 | compress | METRIC - time 3.34s\n",
      "2025-08-16T09:20:15.346611+0000 | compress | METRIC - error 582.45\n",
      "2025-08-16T09:20:15.347399+0000 | compress | METRIC - GPU 0 | usage: 25.54% | total memory: 24 GB\n",
      "2025-08-16T09:20:15.347777+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(10/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 470.34it/s]\n",
      "(11/41): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 66.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:20:24.164930+0000 | compress_modules | INFO - Quantizing model.layers.10.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:20:24.982603+0000 | compress | METRIC - time 0.82s\n",
      "2025-08-16T09:20:24.983529+0000 | compress | METRIC - error 30414.69\n",
      "2025-08-16T09:20:24.984250+0000 | compress | METRIC - GPU 0 | usage: 25.55% | total memory: 24 GB\n",
      "2025-08-16T09:20:24.984625+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:20:24.985286+0000 | compress_modules | INFO - Quantizing model.layers.10.self_attn.k_proj using 512 samples\n",
      "2025-08-16T09:20:25.770865+0000 | compress | METRIC - time 0.79s\n",
      "2025-08-16T09:20:25.771834+0000 | compress | METRIC - error 11236.39\n",
      "2025-08-16T09:20:25.772562+0000 | compress | METRIC - GPU 0 | usage: 25.55% | total memory: 24 GB\n",
      "2025-08-16T09:20:25.772948+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:20:25.773667+0000 | compress_modules | INFO - Quantizing model.layers.10.self_attn.v_proj using 512 samples\n",
      "2025-08-16T09:20:26.554333+0000 | compress | METRIC - time 0.78s\n",
      "2025-08-16T09:20:26.555256+0000 | compress | METRIC - error 2265.56\n",
      "2025-08-16T09:20:26.555970+0000 | compress | METRIC - GPU 0 | usage: 25.55% | total memory: 24 GB\n",
      "2025-08-16T09:20:26.556339+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:20:26.557063+0000 | compress_modules | INFO - Quantizing model.layers.10.self_attn.o_proj using 512 samples\n",
      "2025-08-16T09:20:27.340822+0000 | compress | METRIC - time 0.78s\n",
      "2025-08-16T09:20:27.341735+0000 | compress | METRIC - error 205.18\n",
      "2025-08-16T09:20:27.342424+0000 | compress | METRIC - GPU 0 | usage: 25.55% | total memory: 24 GB\n",
      "2025-08-16T09:20:27.342778+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:20:27.343503+0000 | compress_modules | INFO - Quantizing model.layers.10.mlp.gate_proj using 512 samples\n",
      "2025-08-16T09:20:28.178769+0000 | compress | METRIC - time 0.83s\n",
      "2025-08-16T09:20:28.179664+0000 | compress | METRIC - error 12526.62\n",
      "2025-08-16T09:20:28.180472+0000 | compress | METRIC - GPU 0 | usage: 25.55% | total memory: 24 GB\n",
      "2025-08-16T09:20:28.180849+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:20:28.181669+0000 | compress_modules | INFO - Quantizing model.layers.10.mlp.up_proj using 512 samples\n",
      "2025-08-16T09:20:29.013314+0000 | compress | METRIC - time 0.83s\n",
      "2025-08-16T09:20:29.014265+0000 | compress | METRIC - error 242.94\n",
      "2025-08-16T09:20:29.015093+0000 | compress | METRIC - GPU 0 | usage: 25.55% | total memory: 24 GB\n",
      "2025-08-16T09:20:29.015549+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:20:29.016412+0000 | compress_modules | INFO - Quantizing model.layers.10.mlp.down_proj using 512 samples\n",
      "2025-08-16T09:20:32.437543+0000 | compress | METRIC - time 3.42s\n",
      "2025-08-16T09:20:32.439359+0000 | compress | METRIC - error 645.26\n",
      "2025-08-16T09:20:32.440037+0000 | compress | METRIC - GPU 0 | usage: 25.55% | total memory: 24 GB\n",
      "2025-08-16T09:20:32.440452+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(11/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 468.71it/s]\n",
      "(12/41): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 66.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:20:41.269110+0000 | compress_modules | INFO - Quantizing model.layers.11.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:20:42.091831+0000 | compress | METRIC - time 0.82s\n",
      "2025-08-16T09:20:42.092812+0000 | compress | METRIC - error 29898.63\n",
      "2025-08-16T09:20:42.093636+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:20:42.094198+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:20:42.094855+0000 | compress_modules | INFO - Quantizing model.layers.11.self_attn.k_proj using 512 samples\n",
      "2025-08-16T09:20:42.881229+0000 | compress | METRIC - time 0.79s\n",
      "2025-08-16T09:20:42.882225+0000 | compress | METRIC - error 12083.06\n",
      "2025-08-16T09:20:42.883072+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:20:42.883508+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:20:42.884365+0000 | compress_modules | INFO - Quantizing model.layers.11.self_attn.v_proj using 512 samples\n",
      "2025-08-16T09:20:43.669034+0000 | compress | METRIC - time 0.78s\n",
      "2025-08-16T09:20:43.669979+0000 | compress | METRIC - error 1885.23\n",
      "2025-08-16T09:20:43.670600+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:20:43.670999+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:20:43.671631+0000 | compress_modules | INFO - Quantizing model.layers.11.self_attn.o_proj using 512 samples\n",
      "2025-08-16T09:20:44.459411+0000 | compress | METRIC - time 0.79s\n",
      "2025-08-16T09:20:44.460348+0000 | compress | METRIC - error 317.82\n",
      "2025-08-16T09:20:44.461045+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:20:44.461423+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:20:44.462071+0000 | compress_modules | INFO - Quantizing model.layers.11.mlp.gate_proj using 512 samples\n",
      "2025-08-16T09:20:45.293974+0000 | compress | METRIC - time 0.83s\n",
      "2025-08-16T09:20:45.295065+0000 | compress | METRIC - error 10279.94\n",
      "2025-08-16T09:20:45.296027+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:20:45.296472+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:20:45.297323+0000 | compress_modules | INFO - Quantizing model.layers.11.mlp.up_proj using 512 samples\n",
      "2025-08-16T09:20:46.135231+0000 | compress | METRIC - time 0.84s\n",
      "2025-08-16T09:20:46.136189+0000 | compress | METRIC - error 233.64\n",
      "2025-08-16T09:20:46.137016+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:20:46.137470+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:20:46.138297+0000 | compress_modules | INFO - Quantizing model.layers.11.mlp.down_proj using 512 samples\n",
      "2025-08-16T09:20:49.537006+0000 | compress | METRIC - time 3.40s\n",
      "2025-08-16T09:20:49.538639+0000 | compress | METRIC - error 684.68\n",
      "2025-08-16T09:20:49.539375+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:20:49.539826+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(12/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 467.61it/s]\n",
      "(13/41): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 66.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:20:58.383503+0000 | compress_modules | INFO - Quantizing model.layers.12.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:20:59.198113+0000 | compress | METRIC - time 0.81s\n",
      "2025-08-16T09:20:59.199089+0000 | compress | METRIC - error 45231.54\n",
      "2025-08-16T09:20:59.199697+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:20:59.200075+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:20:59.200712+0000 | compress_modules | INFO - Quantizing model.layers.12.self_attn.k_proj using 512 samples\n",
      "2025-08-16T09:20:59.984556+0000 | compress | METRIC - time 0.78s\n",
      "2025-08-16T09:20:59.985570+0000 | compress | METRIC - error 22084.02\n",
      "2025-08-16T09:20:59.986355+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:20:59.986716+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:20:59.987373+0000 | compress_modules | INFO - Quantizing model.layers.12.self_attn.v_proj using 512 samples\n",
      "2025-08-16T09:21:00.779884+0000 | compress | METRIC - time 0.79s\n",
      "2025-08-16T09:21:00.780928+0000 | compress | METRIC - error 2026.55\n",
      "2025-08-16T09:21:00.782046+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:21:00.782439+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:21:00.783182+0000 | compress_modules | INFO - Quantizing model.layers.12.self_attn.o_proj using 512 samples\n",
      "2025-08-16T09:21:01.571599+0000 | compress | METRIC - time 0.79s\n",
      "2025-08-16T09:21:01.572574+0000 | compress | METRIC - error 287.05\n",
      "2025-08-16T09:21:01.573320+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:21:01.573695+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:21:01.574341+0000 | compress_modules | INFO - Quantizing model.layers.12.mlp.gate_proj using 512 samples\n",
      "2025-08-16T09:21:02.403244+0000 | compress | METRIC - time 0.83s\n",
      "2025-08-16T09:21:02.404270+0000 | compress | METRIC - error 11191.66\n",
      "2025-08-16T09:21:02.404943+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:21:02.405301+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:21:02.405972+0000 | compress_modules | INFO - Quantizing model.layers.12.mlp.up_proj using 512 samples\n",
      "2025-08-16T09:21:03.244921+0000 | compress | METRIC - time 0.84s\n",
      "2025-08-16T09:21:03.245884+0000 | compress | METRIC - error 246.24\n",
      "2025-08-16T09:21:03.246571+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:21:03.246951+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:21:03.247593+0000 | compress_modules | INFO - Quantizing model.layers.12.mlp.down_proj using 512 samples\n",
      "2025-08-16T09:21:06.646948+0000 | compress | METRIC - time 3.40s\n",
      "2025-08-16T09:21:06.648637+0000 | compress | METRIC - error 749.59\n",
      "2025-08-16T09:21:06.649661+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:21:06.650046+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(13/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 466.46it/s]\n",
      "(14/41): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 66.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:21:15.532568+0000 | compress_modules | INFO - Quantizing model.layers.13.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:21:16.347391+0000 | compress | METRIC - time 0.81s\n",
      "2025-08-16T09:21:16.348387+0000 | compress | METRIC - error 44073.83\n",
      "2025-08-16T09:21:16.349086+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:21:16.349658+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:21:16.350230+0000 | compress_modules | INFO - Quantizing model.layers.13.self_attn.k_proj using 512 samples\n",
      "2025-08-16T09:21:17.134383+0000 | compress | METRIC - time 0.78s\n",
      "2025-08-16T09:21:17.135359+0000 | compress | METRIC - error 21831.96\n",
      "2025-08-16T09:21:17.136134+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:21:17.136577+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:21:17.137437+0000 | compress_modules | INFO - Quantizing model.layers.13.self_attn.v_proj using 512 samples\n",
      "2025-08-16T09:21:17.919102+0000 | compress | METRIC - time 0.78s\n",
      "2025-08-16T09:21:17.920042+0000 | compress | METRIC - error 2605.03\n",
      "2025-08-16T09:21:17.920876+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:21:17.921325+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:21:17.922134+0000 | compress_modules | INFO - Quantizing model.layers.13.self_attn.o_proj using 512 samples\n",
      "2025-08-16T09:21:18.714602+0000 | compress | METRIC - time 0.79s\n",
      "2025-08-16T09:21:18.715565+0000 | compress | METRIC - error 289.66\n",
      "2025-08-16T09:21:18.716388+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:21:18.716836+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:21:18.717657+0000 | compress_modules | INFO - Quantizing model.layers.13.mlp.gate_proj using 512 samples\n",
      "2025-08-16T09:21:19.536455+0000 | compress | METRIC - time 0.82s\n",
      "2025-08-16T09:21:19.537455+0000 | compress | METRIC - error 10588.54\n",
      "2025-08-16T09:21:19.538254+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:21:19.538698+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:21:19.539480+0000 | compress_modules | INFO - Quantizing model.layers.13.mlp.up_proj using 512 samples\n",
      "2025-08-16T09:21:20.365883+0000 | compress | METRIC - time 0.83s\n",
      "2025-08-16T09:21:20.366833+0000 | compress | METRIC - error 252.93\n",
      "2025-08-16T09:21:20.367628+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:21:20.368091+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:21:20.368938+0000 | compress_modules | INFO - Quantizing model.layers.13.mlp.down_proj using 512 samples\n",
      "2025-08-16T09:21:23.746183+0000 | compress | METRIC - time 3.38s\n",
      "2025-08-16T09:21:23.747832+0000 | compress | METRIC - error 817.99\n",
      "2025-08-16T09:21:23.748620+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:21:23.749225+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(14/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 469.78it/s]\n",
      "(15/41): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 66.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:21:32.572384+0000 | compress_modules | INFO - Quantizing model.layers.14.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:21:33.389502+0000 | compress | METRIC - time 0.82s\n",
      "2025-08-16T09:21:33.390539+0000 | compress | METRIC - error 46560.04\n",
      "2025-08-16T09:21:33.391303+0000 | compress | METRIC - GPU 0 | usage: 25.50% | total memory: 24 GB\n",
      "2025-08-16T09:21:33.391667+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:21:33.392333+0000 | compress_modules | INFO - Quantizing model.layers.14.self_attn.k_proj using 512 samples\n",
      "2025-08-16T09:21:34.175233+0000 | compress | METRIC - time 0.78s\n",
      "2025-08-16T09:21:34.176194+0000 | compress | METRIC - error 23445.62\n",
      "2025-08-16T09:21:34.177221+0000 | compress | METRIC - GPU 0 | usage: 25.50% | total memory: 24 GB\n",
      "2025-08-16T09:21:34.177600+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:21:34.178273+0000 | compress_modules | INFO - Quantizing model.layers.14.self_attn.v_proj using 512 samples\n",
      "2025-08-16T09:21:34.956990+0000 | compress | METRIC - time 0.78s\n",
      "2025-08-16T09:21:34.957960+0000 | compress | METRIC - error 2838.49\n",
      "2025-08-16T09:21:34.958625+0000 | compress | METRIC - GPU 0 | usage: 25.50% | total memory: 24 GB\n",
      "2025-08-16T09:21:34.959156+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:21:34.959846+0000 | compress_modules | INFO - Quantizing model.layers.14.self_attn.o_proj using 512 samples\n",
      "2025-08-16T09:21:35.747605+0000 | compress | METRIC - time 0.79s\n",
      "2025-08-16T09:21:35.748569+0000 | compress | METRIC - error 281.90\n",
      "2025-08-16T09:21:35.749191+0000 | compress | METRIC - GPU 0 | usage: 25.50% | total memory: 24 GB\n",
      "2025-08-16T09:21:35.749601+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:21:35.750451+0000 | compress_modules | INFO - Quantizing model.layers.14.mlp.gate_proj using 512 samples\n",
      "2025-08-16T09:21:36.568858+0000 | compress | METRIC - time 0.82s\n",
      "2025-08-16T09:21:36.569774+0000 | compress | METRIC - error 11228.13\n",
      "2025-08-16T09:21:36.570404+0000 | compress | METRIC - GPU 0 | usage: 25.50% | total memory: 24 GB\n",
      "2025-08-16T09:21:36.570870+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:21:36.571669+0000 | compress_modules | INFO - Quantizing model.layers.14.mlp.up_proj using 512 samples\n",
      "2025-08-16T09:21:37.389553+0000 | compress | METRIC - time 0.82s\n",
      "2025-08-16T09:21:37.390528+0000 | compress | METRIC - error 260.30\n",
      "2025-08-16T09:21:37.391101+0000 | compress | METRIC - GPU 0 | usage: 25.50% | total memory: 24 GB\n",
      "2025-08-16T09:21:37.391629+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:21:37.392378+0000 | compress_modules | INFO - Quantizing model.layers.14.mlp.down_proj using 512 samples\n",
      "2025-08-16T09:21:40.758688+0000 | compress | METRIC - time 3.37s\n",
      "2025-08-16T09:21:40.760353+0000 | compress | METRIC - error 932.23\n",
      "2025-08-16T09:21:40.760950+0000 | compress | METRIC - GPU 0 | usage: 25.50% | total memory: 24 GB\n",
      "2025-08-16T09:21:40.761346+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(15/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 468.43it/s]\n",
      "(16/41): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 66.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:21:49.551322+0000 | compress_modules | INFO - Quantizing model.layers.15.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:21:50.413707+0000 | compress | METRIC - time 0.86s\n",
      "2025-08-16T09:21:50.414647+0000 | compress | METRIC - error 44732.01\n",
      "2025-08-16T09:21:50.415358+0000 | compress | METRIC - GPU 0 | usage: 25.51% | total memory: 24 GB\n",
      "2025-08-16T09:21:50.415709+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:21:50.416439+0000 | compress_modules | INFO - Quantizing model.layers.15.self_attn.k_proj using 512 samples\n",
      "2025-08-16T09:21:51.201907+0000 | compress | METRIC - time 0.79s\n",
      "2025-08-16T09:21:51.202873+0000 | compress | METRIC - error 18848.61\n",
      "2025-08-16T09:21:51.203381+0000 | compress | METRIC - GPU 0 | usage: 25.51% | total memory: 24 GB\n",
      "2025-08-16T09:21:51.203750+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:21:51.204571+0000 | compress_modules | INFO - Quantizing model.layers.15.self_attn.v_proj using 512 samples\n",
      "2025-08-16T09:21:51.983860+0000 | compress | METRIC - time 0.78s\n",
      "2025-08-16T09:21:51.984832+0000 | compress | METRIC - error 3025.22\n",
      "2025-08-16T09:21:51.985366+0000 | compress | METRIC - GPU 0 | usage: 25.51% | total memory: 24 GB\n",
      "2025-08-16T09:21:51.985698+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:21:51.986455+0000 | compress_modules | INFO - Quantizing model.layers.15.self_attn.o_proj using 512 samples\n",
      "2025-08-16T09:21:52.767819+0000 | compress | METRIC - time 0.78s\n",
      "2025-08-16T09:21:52.768721+0000 | compress | METRIC - error 371.62\n",
      "2025-08-16T09:21:52.769378+0000 | compress | METRIC - GPU 0 | usage: 25.51% | total memory: 24 GB\n",
      "2025-08-16T09:21:52.769738+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:21:52.770403+0000 | compress_modules | INFO - Quantizing model.layers.15.mlp.gate_proj using 512 samples\n",
      "2025-08-16T09:21:53.589642+0000 | compress | METRIC - time 0.82s\n",
      "2025-08-16T09:21:53.590614+0000 | compress | METRIC - error 11306.10\n",
      "2025-08-16T09:21:53.591394+0000 | compress | METRIC - GPU 0 | usage: 25.51% | total memory: 24 GB\n",
      "2025-08-16T09:21:53.591961+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:21:53.592730+0000 | compress_modules | INFO - Quantizing model.layers.15.mlp.up_proj using 512 samples\n",
      "2025-08-16T09:21:54.410176+0000 | compress | METRIC - time 0.82s\n",
      "2025-08-16T09:21:54.411174+0000 | compress | METRIC - error 254.61\n",
      "2025-08-16T09:21:54.411909+0000 | compress | METRIC - GPU 0 | usage: 25.51% | total memory: 24 GB\n",
      "2025-08-16T09:21:54.412264+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:21:54.412949+0000 | compress_modules | INFO - Quantizing model.layers.15.mlp.down_proj using 512 samples\n",
      "2025-08-16T09:21:57.769350+0000 | compress | METRIC - time 3.36s\n",
      "2025-08-16T09:21:57.771553+0000 | compress | METRIC - error 1289.63\n",
      "2025-08-16T09:21:57.772352+0000 | compress | METRIC - GPU 0 | usage: 25.51% | total memory: 24 GB\n",
      "2025-08-16T09:21:57.772776+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(16/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 466.67it/s]\n",
      "(17/41): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 66.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:22:06.562028+0000 | compress_modules | INFO - Quantizing model.layers.16.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:22:07.368460+0000 | compress | METRIC - time 0.81s\n",
      "2025-08-16T09:22:07.369404+0000 | compress | METRIC - error 50821.28\n",
      "2025-08-16T09:22:07.370008+0000 | compress | METRIC - GPU 0 | usage: 25.52% | total memory: 24 GB\n",
      "2025-08-16T09:22:07.370372+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:22:07.371007+0000 | compress_modules | INFO - Quantizing model.layers.16.self_attn.k_proj using 512 samples\n",
      "2025-08-16T09:22:08.151284+0000 | compress | METRIC - time 0.78s\n",
      "2025-08-16T09:22:08.152226+0000 | compress | METRIC - error 18177.61\n",
      "2025-08-16T09:22:08.152869+0000 | compress | METRIC - GPU 0 | usage: 25.52% | total memory: 24 GB\n",
      "2025-08-16T09:22:08.153236+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:22:08.153919+0000 | compress_modules | INFO - Quantizing model.layers.16.self_attn.v_proj using 512 samples\n",
      "2025-08-16T09:22:08.931940+0000 | compress | METRIC - time 0.78s\n",
      "2025-08-16T09:22:08.932932+0000 | compress | METRIC - error 4910.02\n",
      "2025-08-16T09:22:08.933613+0000 | compress | METRIC - GPU 0 | usage: 25.52% | total memory: 24 GB\n",
      "2025-08-16T09:22:08.934007+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:22:08.934655+0000 | compress_modules | INFO - Quantizing model.layers.16.self_attn.o_proj using 512 samples\n",
      "2025-08-16T09:22:09.715937+0000 | compress | METRIC - time 0.78s\n",
      "2025-08-16T09:22:09.716966+0000 | compress | METRIC - error 420.83\n",
      "2025-08-16T09:22:09.717635+0000 | compress | METRIC - GPU 0 | usage: 25.52% | total memory: 24 GB\n",
      "2025-08-16T09:22:09.718023+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:22:09.718650+0000 | compress_modules | INFO - Quantizing model.layers.16.mlp.gate_proj using 512 samples\n",
      "2025-08-16T09:22:10.543062+0000 | compress | METRIC - time 0.82s\n",
      "2025-08-16T09:22:10.544087+0000 | compress | METRIC - error 11669.64\n",
      "2025-08-16T09:22:10.544751+0000 | compress | METRIC - GPU 0 | usage: 25.52% | total memory: 24 GB\n",
      "2025-08-16T09:22:10.545152+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:22:10.545774+0000 | compress_modules | INFO - Quantizing model.layers.16.mlp.up_proj using 512 samples\n",
      "2025-08-16T09:22:11.370386+0000 | compress | METRIC - time 0.82s\n",
      "2025-08-16T09:22:11.371369+0000 | compress | METRIC - error 267.07\n",
      "2025-08-16T09:22:11.372023+0000 | compress | METRIC - GPU 0 | usage: 25.52% | total memory: 24 GB\n",
      "2025-08-16T09:22:11.372379+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:22:11.373040+0000 | compress_modules | INFO - Quantizing model.layers.16.mlp.down_proj using 512 samples\n",
      "2025-08-16T09:22:14.716015+0000 | compress | METRIC - time 3.34s\n",
      "2025-08-16T09:22:14.717656+0000 | compress | METRIC - error 1384.61\n",
      "2025-08-16T09:22:14.718487+0000 | compress | METRIC - GPU 0 | usage: 25.52% | total memory: 24 GB\n",
      "2025-08-16T09:22:14.719005+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(17/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 472.70it/s]\n",
      "(18/41): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 66.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:22:23.473195+0000 | compress_modules | INFO - Quantizing model.layers.17.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:22:24.307419+0000 | compress | METRIC - time 0.83s\n",
      "2025-08-16T09:22:24.308429+0000 | compress | METRIC - error 45939.96\n",
      "2025-08-16T09:22:24.309158+0000 | compress | METRIC - GPU 0 | usage: 25.53% | total memory: 24 GB\n",
      "2025-08-16T09:22:24.309535+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:22:24.310211+0000 | compress_modules | INFO - Quantizing model.layers.17.self_attn.k_proj using 512 samples\n",
      "2025-08-16T09:22:25.097242+0000 | compress | METRIC - time 0.79s\n",
      "2025-08-16T09:22:25.098221+0000 | compress | METRIC - error 22757.23\n",
      "2025-08-16T09:22:25.098968+0000 | compress | METRIC - GPU 0 | usage: 25.53% | total memory: 24 GB\n",
      "2025-08-16T09:22:25.099334+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:22:25.100022+0000 | compress_modules | INFO - Quantizing model.layers.17.self_attn.v_proj using 512 samples\n",
      "2025-08-16T09:22:25.922070+0000 | compress | METRIC - time 0.82s\n",
      "2025-08-16T09:22:25.923012+0000 | compress | METRIC - error 4150.37\n",
      "2025-08-16T09:22:25.923662+0000 | compress | METRIC - GPU 0 | usage: 25.53% | total memory: 24 GB\n",
      "2025-08-16T09:22:25.924066+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:22:25.924717+0000 | compress_modules | INFO - Quantizing model.layers.17.self_attn.o_proj using 512 samples\n",
      "2025-08-16T09:22:26.710751+0000 | compress | METRIC - time 0.79s\n",
      "2025-08-16T09:22:26.711764+0000 | compress | METRIC - error 775.32\n",
      "2025-08-16T09:22:26.712282+0000 | compress | METRIC - GPU 0 | usage: 25.53% | total memory: 24 GB\n",
      "2025-08-16T09:22:26.712653+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:22:26.713435+0000 | compress_modules | INFO - Quantizing model.layers.17.mlp.gate_proj using 512 samples\n",
      "2025-08-16T09:22:27.527541+0000 | compress | METRIC - time 0.81s\n",
      "2025-08-16T09:22:27.528462+0000 | compress | METRIC - error 13240.02\n",
      "2025-08-16T09:22:27.529168+0000 | compress | METRIC - GPU 0 | usage: 25.53% | total memory: 24 GB\n",
      "2025-08-16T09:22:27.529532+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:22:27.530194+0000 | compress_modules | INFO - Quantizing model.layers.17.mlp.up_proj using 512 samples\n",
      "2025-08-16T09:22:28.359842+0000 | compress | METRIC - time 0.83s\n",
      "2025-08-16T09:22:28.360817+0000 | compress | METRIC - error 293.21\n",
      "2025-08-16T09:22:28.361466+0000 | compress | METRIC - GPU 0 | usage: 25.53% | total memory: 24 GB\n",
      "2025-08-16T09:22:28.361848+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:22:28.362508+0000 | compress_modules | INFO - Quantizing model.layers.17.mlp.down_proj using 512 samples\n",
      "2025-08-16T09:22:31.704037+0000 | compress | METRIC - time 3.34s\n",
      "2025-08-16T09:22:31.705662+0000 | compress | METRIC - error 1621.41\n",
      "2025-08-16T09:22:31.706188+0000 | compress | METRIC - GPU 0 | usage: 25.53% | total memory: 24 GB\n",
      "2025-08-16T09:22:31.706534+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(18/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 470.80it/s]\n",
      "(19/41): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 66.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:22:40.485376+0000 | compress_modules | INFO - Quantizing model.layers.18.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:22:41.306885+0000 | compress | METRIC - time 0.82s\n",
      "2025-08-16T09:22:41.307862+0000 | compress | METRIC - error 45650.38\n",
      "2025-08-16T09:22:41.308573+0000 | compress | METRIC - GPU 0 | usage: 25.54% | total memory: 24 GB\n",
      "2025-08-16T09:22:41.308954+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:22:41.309607+0000 | compress_modules | INFO - Quantizing model.layers.18.self_attn.k_proj using 512 samples\n",
      "2025-08-16T09:22:42.088756+0000 | compress | METRIC - time 0.78s\n",
      "2025-08-16T09:22:42.089691+0000 | compress | METRIC - error 22239.74\n",
      "2025-08-16T09:22:42.090442+0000 | compress | METRIC - GPU 0 | usage: 25.54% | total memory: 24 GB\n",
      "2025-08-16T09:22:42.090863+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:22:42.091519+0000 | compress_modules | INFO - Quantizing model.layers.18.self_attn.v_proj using 512 samples\n",
      "2025-08-16T09:22:42.878364+0000 | compress | METRIC - time 0.79s\n",
      "2025-08-16T09:22:42.879321+0000 | compress | METRIC - error 5686.78\n",
      "2025-08-16T09:22:42.880433+0000 | compress | METRIC - GPU 0 | usage: 25.54% | total memory: 24 GB\n",
      "2025-08-16T09:22:42.880860+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:22:42.881528+0000 | compress_modules | INFO - Quantizing model.layers.18.self_attn.o_proj using 512 samples\n",
      "2025-08-16T09:22:43.676443+0000 | compress | METRIC - time 0.79s\n",
      "2025-08-16T09:22:43.677397+0000 | compress | METRIC - error 549.13\n",
      "2025-08-16T09:22:43.678066+0000 | compress | METRIC - GPU 0 | usage: 25.54% | total memory: 24 GB\n",
      "2025-08-16T09:22:43.678452+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:22:43.679105+0000 | compress_modules | INFO - Quantizing model.layers.18.mlp.gate_proj using 512 samples\n",
      "2025-08-16T09:22:44.498971+0000 | compress | METRIC - time 0.82s\n",
      "2025-08-16T09:22:44.499936+0000 | compress | METRIC - error 12788.10\n",
      "2025-08-16T09:22:44.500638+0000 | compress | METRIC - GPU 0 | usage: 25.54% | total memory: 24 GB\n",
      "2025-08-16T09:22:44.501056+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:22:44.501704+0000 | compress_modules | INFO - Quantizing model.layers.18.mlp.up_proj using 512 samples\n",
      "2025-08-16T09:22:45.323974+0000 | compress | METRIC - time 0.82s\n",
      "2025-08-16T09:22:45.324970+0000 | compress | METRIC - error 271.63\n",
      "2025-08-16T09:22:45.325650+0000 | compress | METRIC - GPU 0 | usage: 25.54% | total memory: 24 GB\n",
      "2025-08-16T09:22:45.326048+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:22:45.326692+0000 | compress_modules | INFO - Quantizing model.layers.18.mlp.down_proj using 512 samples\n",
      "2025-08-16T09:22:48.687536+0000 | compress | METRIC - time 3.36s\n",
      "2025-08-16T09:22:48.689219+0000 | compress | METRIC - error 1294.02\n",
      "2025-08-16T09:22:48.690296+0000 | compress | METRIC - GPU 0 | usage: 25.54% | total memory: 24 GB\n",
      "2025-08-16T09:22:48.690677+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(19/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 469.84it/s]\n",
      "(20/41): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 66.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:22:57.482368+0000 | compress_modules | INFO - Quantizing model.layers.19.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:22:58.347440+0000 | compress | METRIC - time 0.86s\n",
      "2025-08-16T09:22:58.348466+0000 | compress | METRIC - error 49685.23\n",
      "2025-08-16T09:22:58.349236+0000 | compress | METRIC - GPU 0 | usage: 25.54% | total memory: 24 GB\n",
      "2025-08-16T09:22:58.349602+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:22:58.350316+0000 | compress_modules | INFO - Quantizing model.layers.19.self_attn.k_proj using 512 samples\n",
      "2025-08-16T09:22:59.140507+0000 | compress | METRIC - time 0.79s\n",
      "2025-08-16T09:22:59.141496+0000 | compress | METRIC - error 23585.09\n",
      "2025-08-16T09:22:59.142272+0000 | compress | METRIC - GPU 0 | usage: 25.54% | total memory: 24 GB\n",
      "2025-08-16T09:22:59.142630+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:22:59.143351+0000 | compress_modules | INFO - Quantizing model.layers.19.self_attn.v_proj using 512 samples\n",
      "2025-08-16T09:22:59.941466+0000 | compress | METRIC - time 0.80s\n",
      "2025-08-16T09:22:59.942470+0000 | compress | METRIC - error 3918.59\n",
      "2025-08-16T09:22:59.943226+0000 | compress | METRIC - GPU 0 | usage: 25.54% | total memory: 24 GB\n",
      "2025-08-16T09:22:59.943606+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:22:59.944339+0000 | compress_modules | INFO - Quantizing model.layers.19.self_attn.o_proj using 512 samples\n",
      "2025-08-16T09:23:00.751757+0000 | compress | METRIC - time 0.81s\n",
      "2025-08-16T09:23:00.752840+0000 | compress | METRIC - error 586.52\n",
      "2025-08-16T09:23:00.753779+0000 | compress | METRIC - GPU 0 | usage: 25.54% | total memory: 24 GB\n",
      "2025-08-16T09:23:00.754188+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:23:00.754948+0000 | compress_modules | INFO - Quantizing model.layers.19.mlp.gate_proj using 512 samples\n",
      "2025-08-16T09:23:01.586704+0000 | compress | METRIC - time 0.83s\n",
      "2025-08-16T09:23:01.587714+0000 | compress | METRIC - error 14822.95\n",
      "2025-08-16T09:23:01.588458+0000 | compress | METRIC - GPU 0 | usage: 25.54% | total memory: 24 GB\n",
      "2025-08-16T09:23:01.588842+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:23:01.589542+0000 | compress_modules | INFO - Quantizing model.layers.19.mlp.up_proj using 512 samples\n",
      "2025-08-16T09:23:02.423923+0000 | compress | METRIC - time 0.83s\n",
      "2025-08-16T09:23:02.424935+0000 | compress | METRIC - error 265.84\n",
      "2025-08-16T09:23:02.425622+0000 | compress | METRIC - GPU 0 | usage: 25.54% | total memory: 24 GB\n",
      "2025-08-16T09:23:02.426013+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:23:02.426714+0000 | compress_modules | INFO - Quantizing model.layers.19.mlp.down_proj using 512 samples\n",
      "2025-08-16T09:23:05.872801+0000 | compress | METRIC - time 3.45s\n",
      "2025-08-16T09:23:05.874463+0000 | compress | METRIC - error 1030.53\n",
      "2025-08-16T09:23:05.875293+0000 | compress | METRIC - GPU 0 | usage: 25.54% | total memory: 24 GB\n",
      "2025-08-16T09:23:05.875709+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(20/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 469.68it/s]\n",
      "(21/41): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 66.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:23:14.715557+0000 | compress_modules | INFO - Quantizing model.layers.20.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:23:15.536212+0000 | compress | METRIC - time 0.82s\n",
      "2025-08-16T09:23:15.537194+0000 | compress | METRIC - error 48290.51\n",
      "2025-08-16T09:23:15.538089+0000 | compress | METRIC - GPU 0 | usage: 25.48% | total memory: 24 GB\n",
      "2025-08-16T09:23:15.538544+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:23:15.539402+0000 | compress_modules | INFO - Quantizing model.layers.20.self_attn.k_proj using 512 samples\n",
      "2025-08-16T09:23:16.320681+0000 | compress | METRIC - time 0.78s\n",
      "2025-08-16T09:23:16.321677+0000 | compress | METRIC - error 21581.77\n",
      "2025-08-16T09:23:16.322453+0000 | compress | METRIC - GPU 0 | usage: 25.48% | total memory: 24 GB\n",
      "2025-08-16T09:23:16.322839+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:23:16.323533+0000 | compress_modules | INFO - Quantizing model.layers.20.self_attn.v_proj using 512 samples\n",
      "2025-08-16T09:23:17.111863+0000 | compress | METRIC - time 0.79s\n",
      "2025-08-16T09:23:17.112924+0000 | compress | METRIC - error 4345.33\n",
      "2025-08-16T09:23:17.113648+0000 | compress | METRIC - GPU 0 | usage: 25.48% | total memory: 24 GB\n",
      "2025-08-16T09:23:17.114043+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:23:17.114733+0000 | compress_modules | INFO - Quantizing model.layers.20.self_attn.o_proj using 512 samples\n",
      "2025-08-16T09:23:17.903092+0000 | compress | METRIC - time 0.79s\n",
      "2025-08-16T09:23:17.904145+0000 | compress | METRIC - error 268.97\n",
      "2025-08-16T09:23:17.904897+0000 | compress | METRIC - GPU 0 | usage: 25.48% | total memory: 24 GB\n",
      "2025-08-16T09:23:17.905285+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:23:17.906000+0000 | compress_modules | INFO - Quantizing model.layers.20.mlp.gate_proj using 512 samples\n",
      "2025-08-16T09:23:18.729632+0000 | compress | METRIC - time 0.82s\n",
      "2025-08-16T09:23:18.730650+0000 | compress | METRIC - error 15215.88\n",
      "2025-08-16T09:23:18.731449+0000 | compress | METRIC - GPU 0 | usage: 25.48% | total memory: 24 GB\n",
      "2025-08-16T09:23:18.731830+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:23:18.732556+0000 | compress_modules | INFO - Quantizing model.layers.20.mlp.up_proj using 512 samples\n",
      "2025-08-16T09:23:19.555178+0000 | compress | METRIC - time 0.82s\n",
      "2025-08-16T09:23:19.556134+0000 | compress | METRIC - error 263.25\n",
      "2025-08-16T09:23:19.556627+0000 | compress | METRIC - GPU 0 | usage: 25.48% | total memory: 24 GB\n",
      "2025-08-16T09:23:19.556992+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:23:19.557842+0000 | compress_modules | INFO - Quantizing model.layers.20.mlp.down_proj using 512 samples\n",
      "2025-08-16T09:23:22.927185+0000 | compress | METRIC - time 3.37s\n",
      "2025-08-16T09:23:22.928943+0000 | compress | METRIC - error 925.22\n",
      "2025-08-16T09:23:22.929724+0000 | compress | METRIC - GPU 0 | usage: 25.48% | total memory: 24 GB\n",
      "2025-08-16T09:23:22.930129+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(21/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 468.36it/s]\n",
      "(22/41): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 66.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:23:31.757435+0000 | compress_modules | INFO - Quantizing model.layers.21.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:23:32.568261+0000 | compress | METRIC - time 0.81s\n",
      "2025-08-16T09:23:32.569282+0000 | compress | METRIC - error 45971.88\n",
      "2025-08-16T09:23:32.570045+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:23:32.570456+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:23:32.571194+0000 | compress_modules | INFO - Quantizing model.layers.21.self_attn.k_proj using 512 samples\n",
      "2025-08-16T09:23:33.370634+0000 | compress | METRIC - time 0.80s\n",
      "2025-08-16T09:23:33.371622+0000 | compress | METRIC - error 21119.10\n",
      "2025-08-16T09:23:33.372333+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:23:33.372878+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:23:33.373439+0000 | compress_modules | INFO - Quantizing model.layers.21.self_attn.v_proj using 512 samples\n",
      "2025-08-16T09:23:34.164835+0000 | compress | METRIC - time 0.79s\n",
      "2025-08-16T09:23:34.165846+0000 | compress | METRIC - error 3061.31\n",
      "2025-08-16T09:23:34.166554+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:23:34.166953+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:23:34.167633+0000 | compress_modules | INFO - Quantizing model.layers.21.self_attn.o_proj using 512 samples\n",
      "2025-08-16T09:23:34.966236+0000 | compress | METRIC - time 0.80s\n",
      "2025-08-16T09:23:34.967254+0000 | compress | METRIC - error 270.53\n",
      "2025-08-16T09:23:34.967824+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:23:34.968185+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:23:34.969071+0000 | compress_modules | INFO - Quantizing model.layers.21.mlp.gate_proj using 512 samples\n",
      "2025-08-16T09:23:35.811544+0000 | compress | METRIC - time 0.84s\n",
      "2025-08-16T09:23:35.812603+0000 | compress | METRIC - error 15960.12\n",
      "2025-08-16T09:23:35.813335+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:23:35.813699+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:23:35.814400+0000 | compress_modules | INFO - Quantizing model.layers.21.mlp.up_proj using 512 samples\n",
      "2025-08-16T09:23:36.641423+0000 | compress | METRIC - time 0.83s\n",
      "2025-08-16T09:23:36.642449+0000 | compress | METRIC - error 260.43\n",
      "2025-08-16T09:23:36.643031+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:23:36.643383+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:23:36.644185+0000 | compress_modules | INFO - Quantizing model.layers.21.mlp.down_proj using 512 samples\n",
      "2025-08-16T09:23:39.995454+0000 | compress | METRIC - time 3.35s\n",
      "2025-08-16T09:23:39.997171+0000 | compress | METRIC - error 884.38\n",
      "2025-08-16T09:23:39.997898+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:23:39.998318+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(22/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 466.77it/s]\n",
      "(23/41): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 66.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:23:48.830389+0000 | compress_modules | INFO - Quantizing model.layers.22.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:23:49.652274+0000 | compress | METRIC - time 0.82s\n",
      "2025-08-16T09:23:49.653314+0000 | compress | METRIC - error 46517.13\n",
      "2025-08-16T09:23:49.654094+0000 | compress | METRIC - GPU 0 | usage: 25.50% | total memory: 24 GB\n",
      "2025-08-16T09:23:49.654546+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:23:49.655407+0000 | compress_modules | INFO - Quantizing model.layers.22.self_attn.k_proj using 512 samples\n",
      "2025-08-16T09:23:50.446006+0000 | compress | METRIC - time 0.79s\n",
      "2025-08-16T09:23:50.447004+0000 | compress | METRIC - error 17908.47\n",
      "2025-08-16T09:23:50.447916+0000 | compress | METRIC - GPU 0 | usage: 25.50% | total memory: 24 GB\n",
      "2025-08-16T09:23:50.448504+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:23:50.449152+0000 | compress_modules | INFO - Quantizing model.layers.22.self_attn.v_proj using 512 samples\n",
      "2025-08-16T09:23:51.232467+0000 | compress | METRIC - time 0.78s\n",
      "2025-08-16T09:23:51.233501+0000 | compress | METRIC - error 4965.62\n",
      "2025-08-16T09:23:51.351472+0000 | compress | METRIC - GPU 0 | usage: 25.50% | total memory: 24 GB\n",
      "2025-08-16T09:23:51.352065+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:23:51.352883+0000 | compress_modules | INFO - Quantizing model.layers.22.self_attn.o_proj using 512 samples\n",
      "2025-08-16T09:23:52.128620+0000 | compress | METRIC - time 0.78s\n",
      "2025-08-16T09:23:52.129660+0000 | compress | METRIC - error 207.98\n",
      "2025-08-16T09:23:52.130504+0000 | compress | METRIC - GPU 0 | usage: 25.50% | total memory: 24 GB\n",
      "2025-08-16T09:23:52.130974+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:23:52.131688+0000 | compress_modules | INFO - Quantizing model.layers.22.mlp.gate_proj using 512 samples\n",
      "2025-08-16T09:23:52.943384+0000 | compress | METRIC - time 0.81s\n",
      "2025-08-16T09:23:52.944378+0000 | compress | METRIC - error 16445.67\n",
      "2025-08-16T09:23:52.945118+0000 | compress | METRIC - GPU 0 | usage: 25.50% | total memory: 24 GB\n",
      "2025-08-16T09:23:52.945635+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:23:52.946218+0000 | compress_modules | INFO - Quantizing model.layers.22.mlp.up_proj using 512 samples\n",
      "2025-08-16T09:23:53.770601+0000 | compress | METRIC - time 0.82s\n",
      "2025-08-16T09:23:53.771619+0000 | compress | METRIC - error 260.18\n",
      "2025-08-16T09:23:53.772319+0000 | compress | METRIC - GPU 0 | usage: 25.50% | total memory: 24 GB\n",
      "2025-08-16T09:23:53.772702+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:23:53.773403+0000 | compress_modules | INFO - Quantizing model.layers.22.mlp.down_proj using 512 samples\n",
      "2025-08-16T09:23:57.192682+0000 | compress | METRIC - time 3.42s\n",
      "2025-08-16T09:23:57.194411+0000 | compress | METRIC - error 928.77\n",
      "2025-08-16T09:23:57.195107+0000 | compress | METRIC - GPU 0 | usage: 25.50% | total memory: 24 GB\n",
      "2025-08-16T09:23:57.195473+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(23/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 463.85it/s]\n",
      "(24/41): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 66.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:24:06.036225+0000 | compress_modules | INFO - Quantizing model.layers.23.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:24:06.853759+0000 | compress | METRIC - time 0.82s\n",
      "2025-08-16T09:24:06.854725+0000 | compress | METRIC - error 58195.68\n",
      "2025-08-16T09:24:06.855557+0000 | compress | METRIC - GPU 0 | usage: 25.51% | total memory: 24 GB\n",
      "2025-08-16T09:24:06.855993+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:24:06.856859+0000 | compress_modules | INFO - Quantizing model.layers.23.self_attn.k_proj using 512 samples\n",
      "2025-08-16T09:24:07.640042+0000 | compress | METRIC - time 0.78s\n",
      "2025-08-16T09:24:07.641094+0000 | compress | METRIC - error 27485.05\n",
      "2025-08-16T09:24:07.641914+0000 | compress | METRIC - GPU 0 | usage: 25.51% | total memory: 24 GB\n",
      "2025-08-16T09:24:07.642370+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:24:07.643237+0000 | compress_modules | INFO - Quantizing model.layers.23.self_attn.v_proj using 512 samples\n",
      "2025-08-16T09:24:08.427463+0000 | compress | METRIC - time 0.78s\n",
      "2025-08-16T09:24:08.428389+0000 | compress | METRIC - error 5821.12\n",
      "2025-08-16T09:24:08.429183+0000 | compress | METRIC - GPU 0 | usage: 25.51% | total memory: 24 GB\n",
      "2025-08-16T09:24:08.429774+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:24:08.430428+0000 | compress_modules | INFO - Quantizing model.layers.23.self_attn.o_proj using 512 samples\n",
      "2025-08-16T09:24:09.220706+0000 | compress | METRIC - time 0.79s\n",
      "2025-08-16T09:24:09.221716+0000 | compress | METRIC - error 363.20\n",
      "2025-08-16T09:24:09.222667+0000 | compress | METRIC - GPU 0 | usage: 25.51% | total memory: 24 GB\n",
      "2025-08-16T09:24:09.223120+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:24:09.223982+0000 | compress_modules | INFO - Quantizing model.layers.23.mlp.gate_proj using 512 samples\n",
      "2025-08-16T09:24:10.055750+0000 | compress | METRIC - time 0.83s\n",
      "2025-08-16T09:24:10.056727+0000 | compress | METRIC - error 18295.65\n",
      "2025-08-16T09:24:10.057584+0000 | compress | METRIC - GPU 0 | usage: 25.51% | total memory: 24 GB\n",
      "2025-08-16T09:24:10.058169+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:24:10.058843+0000 | compress_modules | INFO - Quantizing model.layers.23.mlp.up_proj using 512 samples\n",
      "2025-08-16T09:24:10.900537+0000 | compress | METRIC - time 0.84s\n",
      "2025-08-16T09:24:10.901527+0000 | compress | METRIC - error 269.73\n",
      "2025-08-16T09:24:10.902268+0000 | compress | METRIC - GPU 0 | usage: 25.51% | total memory: 24 GB\n",
      "2025-08-16T09:24:10.902633+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:24:10.903286+0000 | compress_modules | INFO - Quantizing model.layers.23.mlp.down_proj using 512 samples\n",
      "2025-08-16T09:24:14.285763+0000 | compress | METRIC - time 3.38s\n",
      "2025-08-16T09:24:14.287441+0000 | compress | METRIC - error 955.49\n",
      "2025-08-16T09:24:14.288421+0000 | compress | METRIC - GPU 0 | usage: 25.51% | total memory: 24 GB\n",
      "2025-08-16T09:24:14.288811+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(24/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 466.22it/s]\n",
      "(25/41): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 66.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:24:23.110930+0000 | compress_modules | INFO - Quantizing model.layers.24.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:24:23.951403+0000 | compress | METRIC - time 0.84s\n",
      "2025-08-16T09:24:23.952438+0000 | compress | METRIC - error 47724.11\n",
      "2025-08-16T09:24:23.953035+0000 | compress | METRIC - GPU 0 | usage: 25.52% | total memory: 24 GB\n",
      "2025-08-16T09:24:23.953448+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:24:23.954357+0000 | compress_modules | INFO - Quantizing model.layers.24.self_attn.k_proj using 512 samples\n",
      "2025-08-16T09:24:24.735055+0000 | compress | METRIC - time 0.78s\n",
      "2025-08-16T09:24:24.736050+0000 | compress | METRIC - error 20773.05\n",
      "2025-08-16T09:24:24.736875+0000 | compress | METRIC - GPU 0 | usage: 25.52% | total memory: 24 GB\n",
      "2025-08-16T09:24:24.737295+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:24:24.738066+0000 | compress_modules | INFO - Quantizing model.layers.24.self_attn.v_proj using 512 samples\n",
      "2025-08-16T09:24:25.521487+0000 | compress | METRIC - time 0.78s\n",
      "2025-08-16T09:24:25.522487+0000 | compress | METRIC - error 4281.92\n",
      "2025-08-16T09:24:25.523231+0000 | compress | METRIC - GPU 0 | usage: 25.52% | total memory: 24 GB\n",
      "2025-08-16T09:24:25.523642+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:24:25.524465+0000 | compress_modules | INFO - Quantizing model.layers.24.self_attn.o_proj using 512 samples\n",
      "2025-08-16T09:24:26.314965+0000 | compress | METRIC - time 0.79s\n",
      "2025-08-16T09:24:26.315929+0000 | compress | METRIC - error 259.41\n",
      "2025-08-16T09:24:26.316704+0000 | compress | METRIC - GPU 0 | usage: 25.52% | total memory: 24 GB\n",
      "2025-08-16T09:24:26.317201+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:24:26.317925+0000 | compress_modules | INFO - Quantizing model.layers.24.mlp.gate_proj using 512 samples\n",
      "2025-08-16T09:24:27.143780+0000 | compress | METRIC - time 0.83s\n",
      "2025-08-16T09:24:27.144846+0000 | compress | METRIC - error 19872.36\n",
      "2025-08-16T09:24:27.145667+0000 | compress | METRIC - GPU 0 | usage: 25.52% | total memory: 24 GB\n",
      "2025-08-16T09:24:27.146120+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:24:27.146955+0000 | compress_modules | INFO - Quantizing model.layers.24.mlp.up_proj using 512 samples\n",
      "2025-08-16T09:24:27.988809+0000 | compress | METRIC - time 0.84s\n",
      "2025-08-16T09:24:27.989760+0000 | compress | METRIC - error 275.82\n",
      "2025-08-16T09:24:27.990611+0000 | compress | METRIC - GPU 0 | usage: 25.52% | total memory: 24 GB\n",
      "2025-08-16T09:24:27.990991+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:24:27.991696+0000 | compress_modules | INFO - Quantizing model.layers.24.mlp.down_proj using 512 samples\n",
      "2025-08-16T09:24:31.381558+0000 | compress | METRIC - time 3.39s\n",
      "2025-08-16T09:24:31.383263+0000 | compress | METRIC - error 1035.89\n",
      "2025-08-16T09:24:31.384020+0000 | compress | METRIC - GPU 0 | usage: 25.52% | total memory: 24 GB\n",
      "2025-08-16T09:24:31.384436+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(25/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 468.43it/s]\n",
      "(26/41): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 66.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:24:40.209442+0000 | compress_modules | INFO - Quantizing model.layers.25.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:24:41.032682+0000 | compress | METRIC - time 0.82s\n",
      "2025-08-16T09:24:41.033656+0000 | compress | METRIC - error 52032.14\n",
      "2025-08-16T09:24:41.034381+0000 | compress | METRIC - GPU 0 | usage: 25.53% | total memory: 24 GB\n",
      "2025-08-16T09:24:41.034739+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:24:41.035446+0000 | compress_modules | INFO - Quantizing model.layers.25.self_attn.k_proj using 512 samples\n",
      "2025-08-16T09:24:41.833926+0000 | compress | METRIC - time 0.80s\n",
      "2025-08-16T09:24:41.834937+0000 | compress | METRIC - error 21003.83\n",
      "2025-08-16T09:24:41.835611+0000 | compress | METRIC - GPU 0 | usage: 25.53% | total memory: 24 GB\n",
      "2025-08-16T09:24:41.836040+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:24:41.836728+0000 | compress_modules | INFO - Quantizing model.layers.25.self_attn.v_proj using 512 samples\n",
      "2025-08-16T09:24:42.624252+0000 | compress | METRIC - time 0.79s\n",
      "2025-08-16T09:24:42.625136+0000 | compress | METRIC - error 5226.86\n",
      "2025-08-16T09:24:42.625851+0000 | compress | METRIC - GPU 0 | usage: 25.53% | total memory: 24 GB\n",
      "2025-08-16T09:24:42.626212+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:24:42.626938+0000 | compress_modules | INFO - Quantizing model.layers.25.self_attn.o_proj using 512 samples\n",
      "2025-08-16T09:24:43.425722+0000 | compress | METRIC - time 0.80s\n",
      "2025-08-16T09:24:43.426758+0000 | compress | METRIC - error 205.15\n",
      "2025-08-16T09:24:43.427466+0000 | compress | METRIC - GPU 0 | usage: 25.53% | total memory: 24 GB\n",
      "2025-08-16T09:24:43.427858+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:24:43.428540+0000 | compress_modules | INFO - Quantizing model.layers.25.mlp.gate_proj using 512 samples\n",
      "2025-08-16T09:24:44.252428+0000 | compress | METRIC - time 0.82s\n",
      "2025-08-16T09:24:44.253425+0000 | compress | METRIC - error 20895.48\n",
      "2025-08-16T09:24:44.254235+0000 | compress | METRIC - GPU 0 | usage: 25.53% | total memory: 24 GB\n",
      "2025-08-16T09:24:44.254604+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:24:44.255293+0000 | compress_modules | INFO - Quantizing model.layers.25.mlp.up_proj using 512 samples\n",
      "2025-08-16T09:24:45.076530+0000 | compress | METRIC - time 0.82s\n",
      "2025-08-16T09:24:45.077516+0000 | compress | METRIC - error 280.50\n",
      "2025-08-16T09:24:45.078272+0000 | compress | METRIC - GPU 0 | usage: 25.53% | total memory: 24 GB\n",
      "2025-08-16T09:24:45.078631+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:24:45.079344+0000 | compress_modules | INFO - Quantizing model.layers.25.mlp.down_proj using 512 samples\n",
      "2025-08-16T09:24:48.465476+0000 | compress | METRIC - time 3.39s\n",
      "2025-08-16T09:24:48.467146+0000 | compress | METRIC - error 1194.88\n",
      "2025-08-16T09:24:48.467662+0000 | compress | METRIC - GPU 0 | usage: 25.53% | total memory: 24 GB\n",
      "2025-08-16T09:24:48.468038+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(26/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 467.48it/s]\n",
      "(27/41): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 65.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:24:57.367255+0000 | compress_modules | INFO - Quantizing model.layers.26.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:24:58.219930+0000 | compress | METRIC - time 0.85s\n",
      "2025-08-16T09:24:58.220966+0000 | compress | METRIC - error 47385.82\n",
      "2025-08-16T09:24:58.221870+0000 | compress | METRIC - GPU 0 | usage: 25.53% | total memory: 24 GB\n",
      "2025-08-16T09:24:58.222303+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:24:58.223161+0000 | compress_modules | INFO - Quantizing model.layers.26.self_attn.k_proj using 512 samples\n",
      "2025-08-16T09:24:59.012175+0000 | compress | METRIC - time 0.79s\n",
      "2025-08-16T09:24:59.013173+0000 | compress | METRIC - error 18852.43\n",
      "2025-08-16T09:24:59.014363+0000 | compress | METRIC - GPU 0 | usage: 25.53% | total memory: 24 GB\n",
      "2025-08-16T09:24:59.014772+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:24:59.015635+0000 | compress_modules | INFO - Quantizing model.layers.26.self_attn.v_proj using 512 samples\n",
      "2025-08-16T09:24:59.804075+0000 | compress | METRIC - time 0.79s\n",
      "2025-08-16T09:24:59.805071+0000 | compress | METRIC - error 7215.85\n",
      "2025-08-16T09:24:59.805969+0000 | compress | METRIC - GPU 0 | usage: 25.53% | total memory: 24 GB\n",
      "2025-08-16T09:24:59.806363+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:24:59.807209+0000 | compress_modules | INFO - Quantizing model.layers.26.self_attn.o_proj using 512 samples\n",
      "2025-08-16T09:25:00.601205+0000 | compress | METRIC - time 0.79s\n",
      "2025-08-16T09:25:00.602205+0000 | compress | METRIC - error 108.18\n",
      "2025-08-16T09:25:00.603077+0000 | compress | METRIC - GPU 0 | usage: 25.53% | total memory: 24 GB\n",
      "2025-08-16T09:25:00.603498+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:25:00.604350+0000 | compress_modules | INFO - Quantizing model.layers.26.mlp.gate_proj using 512 samples\n",
      "2025-08-16T09:25:01.428875+0000 | compress | METRIC - time 0.82s\n",
      "2025-08-16T09:25:01.429803+0000 | compress | METRIC - error 22720.12\n",
      "2025-08-16T09:25:01.430712+0000 | compress | METRIC - GPU 0 | usage: 25.53% | total memory: 24 GB\n",
      "2025-08-16T09:25:01.431162+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:25:01.431983+0000 | compress_modules | INFO - Quantizing model.layers.26.mlp.up_proj using 512 samples\n",
      "2025-08-16T09:25:02.256070+0000 | compress | METRIC - time 0.82s\n",
      "2025-08-16T09:25:02.257071+0000 | compress | METRIC - error 288.40\n",
      "2025-08-16T09:25:02.257980+0000 | compress | METRIC - GPU 0 | usage: 25.53% | total memory: 24 GB\n",
      "2025-08-16T09:25:02.258435+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:25:02.259298+0000 | compress_modules | INFO - Quantizing model.layers.26.mlp.down_proj using 512 samples\n",
      "2025-08-16T09:25:05.644695+0000 | compress | METRIC - time 3.39s\n",
      "2025-08-16T09:25:05.646544+0000 | compress | METRIC - error 1377.18\n",
      "2025-08-16T09:25:05.647253+0000 | compress | METRIC - GPU 0 | usage: 25.53% | total memory: 24 GB\n",
      "2025-08-16T09:25:05.647639+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(27/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 468.26it/s]\n",
      "(28/41): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 66.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:25:14.507126+0000 | compress_modules | INFO - Quantizing model.layers.27.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:25:15.328140+0000 | compress | METRIC - time 0.82s\n",
      "2025-08-16T09:25:15.329145+0000 | compress | METRIC - error 50514.16\n",
      "2025-08-16T09:25:15.329911+0000 | compress | METRIC - GPU 0 | usage: 25.54% | total memory: 24 GB\n",
      "2025-08-16T09:25:15.330277+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:25:15.331033+0000 | compress_modules | INFO - Quantizing model.layers.27.self_attn.k_proj using 512 samples\n",
      "2025-08-16T09:25:16.120458+0000 | compress | METRIC - time 0.79s\n",
      "2025-08-16T09:25:16.121423+0000 | compress | METRIC - error 20067.66\n",
      "2025-08-16T09:25:16.122268+0000 | compress | METRIC - GPU 0 | usage: 25.54% | total memory: 24 GB\n",
      "2025-08-16T09:25:16.122872+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:25:16.123562+0000 | compress_modules | INFO - Quantizing model.layers.27.self_attn.v_proj using 512 samples\n",
      "2025-08-16T09:25:16.907405+0000 | compress | METRIC - time 0.78s\n",
      "2025-08-16T09:25:16.908348+0000 | compress | METRIC - error 5794.95\n",
      "2025-08-16T09:25:16.909181+0000 | compress | METRIC - GPU 0 | usage: 25.54% | total memory: 24 GB\n",
      "2025-08-16T09:25:16.909622+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:25:16.910472+0000 | compress_modules | INFO - Quantizing model.layers.27.self_attn.o_proj using 512 samples\n",
      "2025-08-16T09:25:17.703305+0000 | compress | METRIC - time 0.79s\n",
      "2025-08-16T09:25:17.704244+0000 | compress | METRIC - error 288.02\n",
      "2025-08-16T09:25:17.705054+0000 | compress | METRIC - GPU 0 | usage: 25.54% | total memory: 24 GB\n",
      "2025-08-16T09:25:17.705469+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:25:17.706294+0000 | compress_modules | INFO - Quantizing model.layers.27.mlp.gate_proj using 512 samples\n",
      "2025-08-16T09:25:18.534455+0000 | compress | METRIC - time 0.83s\n",
      "2025-08-16T09:25:18.535616+0000 | compress | METRIC - error 24740.43\n",
      "2025-08-16T09:25:18.536315+0000 | compress | METRIC - GPU 0 | usage: 25.54% | total memory: 24 GB\n",
      "2025-08-16T09:25:18.536739+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:25:18.537598+0000 | compress_modules | INFO - Quantizing model.layers.27.mlp.up_proj using 512 samples\n",
      "2025-08-16T09:25:19.362879+0000 | compress | METRIC - time 0.82s\n",
      "2025-08-16T09:25:19.363903+0000 | compress | METRIC - error 301.94\n",
      "2025-08-16T09:25:19.364669+0000 | compress | METRIC - GPU 0 | usage: 25.54% | total memory: 24 GB\n",
      "2025-08-16T09:25:19.365146+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:25:19.365950+0000 | compress_modules | INFO - Quantizing model.layers.27.mlp.down_proj using 512 samples\n",
      "2025-08-16T09:25:22.725714+0000 | compress | METRIC - time 3.36s\n",
      "2025-08-16T09:25:22.727470+0000 | compress | METRIC - error 1690.55\n",
      "2025-08-16T09:25:22.728278+0000 | compress | METRIC - GPU 0 | usage: 25.54% | total memory: 24 GB\n",
      "2025-08-16T09:25:22.728658+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(28/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 467.95it/s]\n",
      "(29/41): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 66.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:25:31.542130+0000 | compress_modules | INFO - Quantizing model.layers.28.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:25:32.357214+0000 | compress | METRIC - time 0.81s\n",
      "2025-08-16T09:25:32.358168+0000 | compress | METRIC - error 56589.19\n",
      "2025-08-16T09:25:32.359003+0000 | compress | METRIC - GPU 0 | usage: 25.54% | total memory: 24 GB\n",
      "2025-08-16T09:25:32.359581+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:25:32.360284+0000 | compress_modules | INFO - Quantizing model.layers.28.self_attn.k_proj using 512 samples\n",
      "2025-08-16T09:25:33.142207+0000 | compress | METRIC - time 0.78s\n",
      "2025-08-16T09:25:33.143217+0000 | compress | METRIC - error 21200.02\n",
      "2025-08-16T09:25:33.144346+0000 | compress | METRIC - GPU 0 | usage: 25.54% | total memory: 24 GB\n",
      "2025-08-16T09:25:33.144769+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:25:33.145604+0000 | compress_modules | INFO - Quantizing model.layers.28.self_attn.v_proj using 512 samples\n",
      "2025-08-16T09:25:33.926302+0000 | compress | METRIC - time 0.78s\n",
      "2025-08-16T09:25:33.927321+0000 | compress | METRIC - error 7383.59\n",
      "2025-08-16T09:25:33.928181+0000 | compress | METRIC - GPU 0 | usage: 25.54% | total memory: 24 GB\n",
      "2025-08-16T09:25:33.928628+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:25:33.929492+0000 | compress_modules | INFO - Quantizing model.layers.28.self_attn.o_proj using 512 samples\n",
      "2025-08-16T09:25:34.710348+0000 | compress | METRIC - time 0.78s\n",
      "2025-08-16T09:25:34.711386+0000 | compress | METRIC - error 366.53\n",
      "2025-08-16T09:25:34.712262+0000 | compress | METRIC - GPU 0 | usage: 25.54% | total memory: 24 GB\n",
      "2025-08-16T09:25:34.712670+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:25:34.713531+0000 | compress_modules | INFO - Quantizing model.layers.28.mlp.gate_proj using 512 samples\n",
      "2025-08-16T09:25:35.574256+0000 | compress | METRIC - time 0.86s\n",
      "2025-08-16T09:25:35.575215+0000 | compress | METRIC - error 27792.80\n",
      "2025-08-16T09:25:35.576115+0000 | compress | METRIC - GPU 0 | usage: 25.54% | total memory: 24 GB\n",
      "2025-08-16T09:25:35.576550+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:25:35.577437+0000 | compress_modules | INFO - Quantizing model.layers.28.mlp.up_proj using 512 samples\n",
      "2025-08-16T09:25:36.388466+0000 | compress | METRIC - time 0.81s\n",
      "2025-08-16T09:25:36.389425+0000 | compress | METRIC - error 316.32\n",
      "2025-08-16T09:25:36.390453+0000 | compress | METRIC - GPU 0 | usage: 25.54% | total memory: 24 GB\n",
      "2025-08-16T09:25:36.390874+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:25:36.391725+0000 | compress_modules | INFO - Quantizing model.layers.28.mlp.down_proj using 512 samples\n",
      "2025-08-16T09:25:39.757599+0000 | compress | METRIC - time 3.37s\n",
      "2025-08-16T09:25:39.759305+0000 | compress | METRIC - error 2160.54\n",
      "2025-08-16T09:25:39.760168+0000 | compress | METRIC - GPU 0 | usage: 25.54% | total memory: 24 GB\n",
      "2025-08-16T09:25:39.760613+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(29/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 466.60it/s]\n",
      "(30/41): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 66.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:25:48.577480+0000 | compress_modules | INFO - Quantizing model.layers.29.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:25:49.391009+0000 | compress | METRIC - time 0.81s\n",
      "2025-08-16T09:25:49.392054+0000 | compress | METRIC - error 49479.14\n",
      "2025-08-16T09:25:49.392635+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:25:49.393060+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:25:49.393970+0000 | compress_modules | INFO - Quantizing model.layers.29.self_attn.k_proj using 512 samples\n",
      "2025-08-16T09:25:50.178380+0000 | compress | METRIC - time 0.78s\n",
      "2025-08-16T09:25:50.179371+0000 | compress | METRIC - error 17688.41\n",
      "2025-08-16T09:25:50.180212+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:25:50.180638+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:25:50.181460+0000 | compress_modules | INFO - Quantizing model.layers.29.self_attn.v_proj using 512 samples\n",
      "2025-08-16T09:25:50.963058+0000 | compress | METRIC - time 0.78s\n",
      "2025-08-16T09:25:50.964102+0000 | compress | METRIC - error 6960.60\n",
      "2025-08-16T09:25:50.964759+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:25:50.965175+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:25:50.966028+0000 | compress_modules | INFO - Quantizing model.layers.29.self_attn.o_proj using 512 samples\n",
      "2025-08-16T09:25:51.750400+0000 | compress | METRIC - time 0.78s\n",
      "2025-08-16T09:25:51.751363+0000 | compress | METRIC - error 623.87\n",
      "2025-08-16T09:25:51.752224+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:25:51.752636+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:25:51.753458+0000 | compress_modules | INFO - Quantizing model.layers.29.mlp.gate_proj using 512 samples\n",
      "2025-08-16T09:25:52.586341+0000 | compress | METRIC - time 0.83s\n",
      "2025-08-16T09:25:52.587276+0000 | compress | METRIC - error 30613.25\n",
      "2025-08-16T09:25:52.587992+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:25:52.588361+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:25:52.589102+0000 | compress_modules | INFO - Quantizing model.layers.29.mlp.up_proj using 512 samples\n",
      "2025-08-16T09:25:53.426879+0000 | compress | METRIC - time 0.84s\n",
      "2025-08-16T09:25:53.427859+0000 | compress | METRIC - error 337.60\n",
      "2025-08-16T09:25:53.428604+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:25:53.429007+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:25:53.429653+0000 | compress_modules | INFO - Quantizing model.layers.29.mlp.down_proj using 512 samples\n",
      "2025-08-16T09:25:56.817232+0000 | compress | METRIC - time 3.39s\n",
      "2025-08-16T09:25:56.818937+0000 | compress | METRIC - error 2954.43\n",
      "2025-08-16T09:25:56.819810+0000 | compress | METRIC - GPU 0 | usage: 25.49% | total memory: 24 GB\n",
      "2025-08-16T09:25:56.820198+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(30/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 463.56it/s]\n",
      "(31/41): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 66.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:26:05.651840+0000 | compress_modules | INFO - Quantizing model.layers.30.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:26:06.464826+0000 | compress | METRIC - time 0.81s\n",
      "2025-08-16T09:26:06.465753+0000 | compress | METRIC - error 63471.51\n",
      "2025-08-16T09:26:06.466468+0000 | compress | METRIC - GPU 0 | usage: 25.50% | total memory: 24 GB\n",
      "2025-08-16T09:26:06.466844+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:26:06.467532+0000 | compress_modules | INFO - Quantizing model.layers.30.self_attn.k_proj using 512 samples\n",
      "2025-08-16T09:26:07.244017+0000 | compress | METRIC - time 0.78s\n",
      "2025-08-16T09:26:07.245142+0000 | compress | METRIC - error 23335.79\n",
      "2025-08-16T09:26:07.245902+0000 | compress | METRIC - GPU 0 | usage: 25.50% | total memory: 24 GB\n",
      "2025-08-16T09:26:07.246261+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:26:07.246987+0000 | compress_modules | INFO - Quantizing model.layers.30.self_attn.v_proj using 512 samples\n",
      "2025-08-16T09:26:08.026717+0000 | compress | METRIC - time 0.78s\n",
      "2025-08-16T09:26:08.027675+0000 | compress | METRIC - error 12434.04\n",
      "2025-08-16T09:26:08.028359+0000 | compress | METRIC - GPU 0 | usage: 25.50% | total memory: 24 GB\n",
      "2025-08-16T09:26:08.028725+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:26:08.029455+0000 | compress_modules | INFO - Quantizing model.layers.30.self_attn.o_proj using 512 samples\n",
      "2025-08-16T09:26:08.817170+0000 | compress | METRIC - time 0.79s\n",
      "2025-08-16T09:26:08.818241+0000 | compress | METRIC - error 1176.22\n",
      "2025-08-16T09:26:08.819061+0000 | compress | METRIC - GPU 0 | usage: 25.50% | total memory: 24 GB\n",
      "2025-08-16T09:26:08.819505+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:26:08.820352+0000 | compress_modules | INFO - Quantizing model.layers.30.mlp.gate_proj using 512 samples\n",
      "2025-08-16T09:26:09.685642+0000 | compress | METRIC - time 0.86s\n",
      "2025-08-16T09:26:09.686819+0000 | compress | METRIC - error 33994.32\n",
      "2025-08-16T09:26:09.687475+0000 | compress | METRIC - GPU 0 | usage: 25.50% | total memory: 24 GB\n",
      "2025-08-16T09:26:09.687907+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:26:09.688725+0000 | compress_modules | INFO - Quantizing model.layers.30.mlp.up_proj using 512 samples\n",
      "2025-08-16T09:26:10.523926+0000 | compress | METRIC - time 0.83s\n",
      "2025-08-16T09:26:10.524994+0000 | compress | METRIC - error 356.79\n",
      "2025-08-16T09:26:10.525847+0000 | compress | METRIC - GPU 0 | usage: 25.50% | total memory: 24 GB\n",
      "2025-08-16T09:26:10.526302+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:26:10.527131+0000 | compress_modules | INFO - Quantizing model.layers.30.mlp.down_proj using 512 samples\n",
      "2025-08-16T09:26:13.884180+0000 | compress | METRIC - time 3.36s\n",
      "2025-08-16T09:26:13.885966+0000 | compress | METRIC - error 3714.67\n",
      "2025-08-16T09:26:13.886755+0000 | compress | METRIC - GPU 0 | usage: 25.50% | total memory: 24 GB\n",
      "2025-08-16T09:26:13.887233+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(31/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 467.11it/s]\n",
      "(32/41): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 66.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:26:22.695191+0000 | compress_modules | INFO - Quantizing model.layers.31.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:26:23.511911+0000 | compress | METRIC - time 0.82s\n",
      "2025-08-16T09:26:23.512948+0000 | compress | METRIC - error 77332.41\n",
      "2025-08-16T09:26:23.513724+0000 | compress | METRIC - GPU 0 | usage: 25.51% | total memory: 24 GB\n",
      "2025-08-16T09:26:23.514173+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:26:23.515046+0000 | compress_modules | INFO - Quantizing model.layers.31.self_attn.k_proj using 512 samples\n",
      "2025-08-16T09:26:24.293809+0000 | compress | METRIC - time 0.78s\n",
      "2025-08-16T09:26:24.294817+0000 | compress | METRIC - error 28440.25\n",
      "2025-08-16T09:26:24.295628+0000 | compress | METRIC - GPU 0 | usage: 25.51% | total memory: 24 GB\n",
      "2025-08-16T09:26:24.296103+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:26:24.296948+0000 | compress_modules | INFO - Quantizing model.layers.31.self_attn.v_proj using 512 samples\n",
      "2025-08-16T09:26:25.073098+0000 | compress | METRIC - time 0.78s\n",
      "2025-08-16T09:26:25.074328+0000 | compress | METRIC - error 10856.83\n",
      "2025-08-16T09:26:25.075011+0000 | compress | METRIC - GPU 0 | usage: 25.51% | total memory: 24 GB\n",
      "2025-08-16T09:26:25.075594+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:26:25.076271+0000 | compress_modules | INFO - Quantizing model.layers.31.self_attn.o_proj using 512 samples\n",
      "2025-08-16T09:26:25.864833+0000 | compress | METRIC - time 0.79s\n",
      "2025-08-16T09:26:25.865813+0000 | compress | METRIC - error 1150.73\n",
      "2025-08-16T09:26:25.866620+0000 | compress | METRIC - GPU 0 | usage: 25.51% | total memory: 24 GB\n",
      "2025-08-16T09:26:25.867088+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:26:25.867925+0000 | compress_modules | INFO - Quantizing model.layers.31.mlp.gate_proj using 512 samples\n",
      "2025-08-16T09:26:26.718964+0000 | compress | METRIC - time 0.85s\n",
      "2025-08-16T09:26:26.719998+0000 | compress | METRIC - error 36753.63\n",
      "2025-08-16T09:26:26.720639+0000 | compress | METRIC - GPU 0 | usage: 25.51% | total memory: 24 GB\n",
      "2025-08-16T09:26:26.721025+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:26:26.721647+0000 | compress_modules | INFO - Quantizing model.layers.31.mlp.up_proj using 512 samples\n",
      "2025-08-16T09:26:27.572495+0000 | compress | METRIC - time 0.85s\n",
      "2025-08-16T09:26:27.573532+0000 | compress | METRIC - error 374.86\n",
      "2025-08-16T09:26:27.574295+0000 | compress | METRIC - GPU 0 | usage: 25.51% | total memory: 24 GB\n",
      "2025-08-16T09:26:27.574660+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:26:27.575313+0000 | compress_modules | INFO - Quantizing model.layers.31.mlp.down_proj using 512 samples\n",
      "2025-08-16T09:26:31.000080+0000 | compress | METRIC - time 3.42s\n",
      "2025-08-16T09:26:31.001858+0000 | compress | METRIC - error 5505.88\n",
      "2025-08-16T09:26:31.002616+0000 | compress | METRIC - GPU 0 | usage: 25.51% | total memory: 24 GB\n",
      "2025-08-16T09:26:31.003016+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(32/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 468.33it/s]\n",
      "(33/41): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 66.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:26:39.814300+0000 | compress_modules | INFO - Quantizing model.layers.32.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:26:40.642091+0000 | compress | METRIC - time 0.83s\n",
      "2025-08-16T09:26:40.643165+0000 | compress | METRIC - error 59816.77\n",
      "2025-08-16T09:26:40.643885+0000 | compress | METRIC - GPU 0 | usage: 25.52% | total memory: 24 GB\n",
      "2025-08-16T09:26:40.644245+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:26:40.644962+0000 | compress_modules | INFO - Quantizing model.layers.32.self_attn.k_proj using 512 samples\n",
      "2025-08-16T09:26:41.432884+0000 | compress | METRIC - time 0.79s\n",
      "2025-08-16T09:26:41.433904+0000 | compress | METRIC - error 23898.27\n",
      "2025-08-16T09:26:41.434668+0000 | compress | METRIC - GPU 0 | usage: 25.52% | total memory: 24 GB\n",
      "2025-08-16T09:26:41.435041+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:26:41.435714+0000 | compress_modules | INFO - Quantizing model.layers.32.self_attn.v_proj using 512 samples\n",
      "2025-08-16T09:26:42.228843+0000 | compress | METRIC - time 0.79s\n",
      "2025-08-16T09:26:42.229864+0000 | compress | METRIC - error 16446.75\n",
      "2025-08-16T09:26:42.230978+0000 | compress | METRIC - GPU 0 | usage: 25.52% | total memory: 24 GB\n",
      "2025-08-16T09:26:42.231342+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:26:42.232049+0000 | compress_modules | INFO - Quantizing model.layers.32.self_attn.o_proj using 512 samples\n",
      "2025-08-16T09:26:43.027346+0000 | compress | METRIC - time 0.79s\n",
      "2025-08-16T09:26:43.028383+0000 | compress | METRIC - error 1585.10\n",
      "2025-08-16T09:26:43.029082+0000 | compress | METRIC - GPU 0 | usage: 25.52% | total memory: 24 GB\n",
      "2025-08-16T09:26:43.029472+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:26:43.030312+0000 | compress_modules | INFO - Quantizing model.layers.32.mlp.gate_proj using 512 samples\n",
      "2025-08-16T09:26:43.863728+0000 | compress | METRIC - time 0.83s\n",
      "2025-08-16T09:26:43.864727+0000 | compress | METRIC - error 45022.57\n",
      "2025-08-16T09:26:43.865407+0000 | compress | METRIC - GPU 0 | usage: 25.52% | total memory: 24 GB\n",
      "2025-08-16T09:26:43.865834+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:26:43.866616+0000 | compress_modules | INFO - Quantizing model.layers.32.mlp.up_proj using 512 samples\n",
      "2025-08-16T09:26:44.702137+0000 | compress | METRIC - time 0.84s\n",
      "2025-08-16T09:26:44.703187+0000 | compress | METRIC - error 416.26\n",
      "2025-08-16T09:26:44.703914+0000 | compress | METRIC - GPU 0 | usage: 25.52% | total memory: 24 GB\n",
      "2025-08-16T09:26:44.704320+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:26:44.705128+0000 | compress_modules | INFO - Quantizing model.layers.32.mlp.down_proj using 512 samples\n",
      "2025-08-16T09:26:48.100541+0000 | compress | METRIC - time 3.40s\n",
      "2025-08-16T09:26:48.102271+0000 | compress | METRIC - error 8854.21\n",
      "2025-08-16T09:26:48.102918+0000 | compress | METRIC - GPU 0 | usage: 25.52% | total memory: 24 GB\n",
      "2025-08-16T09:26:48.103385+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(33/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 466.70it/s]\n",
      "(34/41): Calibrating: 100%|██████████| 512/512 [00:07<00:00, 66.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:26:56.940557+0000 | compress_modules | INFO - Quantizing model.layers.33.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:26:57.765238+0000 | compress | METRIC - time 0.82s\n",
      "2025-08-16T09:26:57.766257+0000 | compress | METRIC - error 79826.00\n",
      "2025-08-16T09:26:57.766992+0000 | compress | METRIC - GPU 0 | usage: 25.52% | total memory: 24 GB\n",
      "2025-08-16T09:26:57.767388+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:26:57.768158+0000 | compress_modules | INFO - Quantizing model.layers.33.self_attn.k_proj using 512 samples\n",
      "2025-08-16T09:26:58.556898+0000 | compress | METRIC - time 0.79s\n",
      "2025-08-16T09:26:58.557890+0000 | compress | METRIC - error 32549.31\n",
      "2025-08-16T09:26:58.558550+0000 | compress | METRIC - GPU 0 | usage: 25.52% | total memory: 24 GB\n",
      "2025-08-16T09:26:58.558938+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:26:58.559573+0000 | compress_modules | INFO - Quantizing model.layers.33.self_attn.v_proj using 512 samples\n",
      "2025-08-16T09:26:59.341812+0000 | compress | METRIC - time 0.78s\n",
      "2025-08-16T09:26:59.342730+0000 | compress | METRIC - error 24298.73\n",
      "2025-08-16T09:26:59.343424+0000 | compress | METRIC - GPU 0 | usage: 25.52% | total memory: 24 GB\n",
      "2025-08-16T09:26:59.343814+0000 | compress | METRIC - Compressed module size: 2.121728 MB\n",
      "2025-08-16T09:26:59.344471+0000 | compress_modules | INFO - Quantizing model.layers.33.self_attn.o_proj using 512 samples\n",
      "2025-08-16T09:27:00.125445+0000 | compress | METRIC - time 0.78s\n",
      "2025-08-16T09:27:00.126421+0000 | compress | METRIC - error 1925.15\n",
      "2025-08-16T09:27:00.127156+0000 | compress | METRIC - GPU 0 | usage: 25.52% | total memory: 24 GB\n",
      "2025-08-16T09:27:00.127533+0000 | compress | METRIC - Compressed module size: 8.486912 MB\n",
      "2025-08-16T09:27:00.128184+0000 | compress_modules | INFO - Quantizing model.layers.33.mlp.gate_proj using 512 samples\n",
      "2025-08-16T09:27:00.961189+0000 | compress | METRIC - time 0.83s\n",
      "2025-08-16T09:27:00.962172+0000 | compress | METRIC - error 48648.89\n",
      "2025-08-16T09:27:00.962812+0000 | compress | METRIC - GPU 0 | usage: 25.52% | total memory: 24 GB\n",
      "2025-08-16T09:27:00.963182+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:27:00.963839+0000 | compress_modules | INFO - Quantizing model.layers.33.mlp.up_proj using 512 samples\n",
      "2025-08-16T09:27:01.785031+0000 | compress | METRIC - time 0.82s\n",
      "2025-08-16T09:27:01.786018+0000 | compress | METRIC - error 433.23\n",
      "2025-08-16T09:27:01.786774+0000 | compress | METRIC - GPU 0 | usage: 25.52% | total memory: 24 GB\n",
      "2025-08-16T09:27:01.787215+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n",
      "2025-08-16T09:27:01.787867+0000 | compress_modules | INFO - Quantizing model.layers.33.mlp.down_proj using 512 samples\n",
      "2025-08-16T09:27:05.151608+0000 | compress | METRIC - time 3.36s\n",
      "2025-08-16T09:27:05.153749+0000 | compress | METRIC - error 9771.31\n",
      "2025-08-16T09:27:05.154488+0000 | compress | METRIC - GPU 0 | usage: 25.52% | total memory: 24 GB\n",
      "2025-08-16T09:27:05.154910+0000 | compress | METRIC - Compressed module size: 33.947648 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(34/41): Propagating: 100%|██████████| 512/512 [00:01<00:00, 467.21it/s]\n",
      "(35/41): Calibrating:  10%|█         | 53/512 [00:00<00:06, 70.69it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oneshot(\n",
    "    model=model,\n",
    "    dataset=ds,\n",
    "    recipe=recipe,\n",
    "    num_calibration_samples=NUM_CALIBRATION_SAMPLES,\n",
    "    max_seq_length=8196,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105eef1b-2db4-4678-b3d5-9ebc33257424",
   "metadata": {},
   "source": [
    "### Save the Compressed Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712c61fb-8493-40d5-b15c-60f18084aaab",
   "metadata": {},
   "source": [
    "**Explanation**\n",
    "\n",
    "- Naming: appends -W4A16 to distinguish the quantized checkpoint.\n",
    "- **save_compressed=True** stores weights in compact safetensors format for deployment via vLLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47f6d53f-8db5-40a1-874f-14d60b007b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-16T09:28:53.884850+0000 | get_model_compressor | INFO - skip_sparsity_compression_stats set to True. Skipping sparsity compression statistic calculations. No sparsity compressor will be applied.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compressing model: 527it [00:10, 48.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('granite-3.2-2b-instruct-W4A16/tokenizer_config.json',\n",
       " 'granite-3.2-2b-instruct-W4A16/special_tokens_map.json',\n",
       " 'granite-3.2-2b-instruct-W4A16/chat_template.jinja',\n",
       " 'granite-3.2-2b-instruct-W4A16/vocab.json',\n",
       " 'granite-3.2-2b-instruct-W4A16/merges.txt',\n",
       " 'granite-3.2-2b-instruct-W4A16/added_tokens.json',\n",
       " 'granite-3.2-2b-instruct-W4A16/tokenizer.json')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save to disk compressed.\n",
    "MODEL_ID = \"ibm-granite/granite-3.2-2b-instruct\"\n",
    "SAVE_DIR = MODEL_ID.split(\"/\")[-1] + \"-W4A16\"\n",
    "model.save_pretrained(SAVE_DIR, save_compressed=True)\n",
    "tokenizer.save_pretrained(SAVE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed216fb-9c28-4bff-8033-b68c744b4cd9",
   "metadata": {},
   "source": [
    "### Evaluate accuracy in vLLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa02cc91-dfca-4dc1-b150-692e3a309ad3",
   "metadata": {},
   "source": [
    "We can evaluate accuracy with lm_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737002c6-1512-402f-adfa-965660478ece",
   "metadata": {},
   "source": [
    "##### Check GPU memory leftovers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "119cf001-f52b-46a2-a034-1a5ac99d8f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Aug 16 09:29:07 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA L4                      On  |   00000000:31:00.0 Off |                    0 |\n",
      "| N/A   72C    P0             39W /   72W |    5579MiB /  23034MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e2fa79-3e05-4f83-90b7-dd7be66513dc",
   "metadata": {},
   "source": [
    "**IMPORTANT**: After quantizing the model the GPU memory may not be freed (see the above output). You need to **restart the kernel** before evaluating the model to ensure you have enough GPU RAM available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b5eab2-e7f1-4631-b74f-8e5b44d06dc2",
   "metadata": {},
   "source": [
    "#### Install lm_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a8a3ad8-effc-4212-9c5d-ab09d772e73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q lm_eval==v0.4.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7facbbf2-400c-424f-bada-4f224d4f5fd0",
   "metadata": {},
   "source": [
    "#### Install vLLM for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d660bb-9435-4d1c-9599-7e9f8f1ca4ff",
   "metadata": {},
   "source": [
    "Run the following to test accuracy on GSM-8K:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe802b4d-14f4-4379-a05d-e91741770c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llmcompressor 0.6.0 requires numpy<2.0,>=1.17.0, but you have numpy 2.2.6 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q vllm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9575f87-2dcd-4eb6-b433-9ddd56bde6f4",
   "metadata": {},
   "source": [
    "### Evaluation Command"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac46967-6933-4cad-8f11-49bb61a5dd42",
   "metadata": {},
   "source": [
    "- `--model vllm` - Uses vLLM backend for fast, memory-efficient inference on large models \n",
    "- `--model_args` - pretrained=$MODEL_ID: specifies which model to load.\n",
    "- `add_bos_token=true`: ensures a beginning-of-sequence token is added; required for consistent results on math and reasoning tasks \n",
    "- `max_model_len=4096`: sets the context window the model uses for evaluation.\n",
    "- `gpu_memory_utilization=0.5`: limits vLLM to use 50% of GPU memory, allowing to avoid OOM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00fd85be-edf1-4736-86eb-fd93c09c146a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 08-16 09:29:23 [__init__.py:235] Automatically detected platform cuda.\n",
      "2025-08-16:09:29:24,368 INFO     [__main__.py:272] Verbosity set to INFO\n",
      "2025-08-16:09:29:28,939 WARNING  [__main__.py:312]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.\n",
      "2025-08-16:09:29:28,940 INFO     [__main__.py:357] Passed `--trust_remote_code`, setting environment variable `HF_DATASETS_TRUST_REMOTE_CODE=true`\n",
      "2025-08-16:09:29:28,940 INFO     [__main__.py:369] Selected Tasks: ['gsm8k']\n",
      "2025-08-16:09:29:28,942 INFO     [evaluator.py:152] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2025-08-16:09:29:28,942 INFO     [evaluator.py:189] Initializing vllm model, with arguments: {'pretrained': '/opt/app-root/src/granite-3.2-2b-instruct-W4A16', 'add_bos_token': True, 'max_model_len': 4096, 'gpu_memory_utilization': 0.5, 'trust_remote_code': True}\n",
      "INFO 08-16 09:29:35 [config.py:1604] Using max model len 4096\n",
      "INFO 08-16 09:29:36 [config.py:2434] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "INFO 08-16 09:29:36 [core.py:572] Waiting for init message from front-end.\n",
      "INFO 08-16 09:29:36 [core.py:71] Initializing a V1 LLM engine (v0.10.0) with config: model='/opt/app-root/src/granite-3.2-2b-instruct-W4A16', speculative_config=None, tokenizer='/opt/app-root/src/granite-3.2-2b-instruct-W4A16', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=compressed-tensors, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=1234, served_model_name=/opt/app-root/src/granite-3.2-2b-instruct-W4A16, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\",\"vllm.mamba_mixer2\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":512,\"local_cache_dir\":null}\n",
      "INFO 08-16 09:29:37 [parallel_state.py:1102] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "WARNING 08-16 09:29:37 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 08-16 09:29:37 [gpu_model_runner.py:1843] Starting to load model /opt/app-root/src/granite-3.2-2b-instruct-W4A16...\n",
      "INFO 08-16 09:29:38 [gpu_model_runner.py:1875] Loading model from scratch...\n",
      "INFO 08-16 09:29:38 [compressed_tensors_wNa16.py:95] Using MarlinLinearKernel for CompressedTensorsWNA16\n",
      "INFO 08-16 09:29:38 [cuda.py:290] Using Flash Attention backend on V1 engine.\n",
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  3.95it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  3.95it/s]\n",
      "\n",
      "INFO 08-16 09:29:38 [default_loader.py:262] Loading weights took 0.30 seconds\n",
      "INFO 08-16 09:29:39 [gpu_model_runner.py:1892] Model loading took 1.4034 GiB and 0.568781 seconds\n",
      "INFO 08-16 09:29:50 [backends.py:530] Using cache directory: /opt/app-root/src/.cache/vllm/torch_compile_cache/81c95951ee/rank_0_0/backbone for vLLM's torch.compile\n",
      "INFO 08-16 09:29:50 [backends.py:541] Dynamo bytecode transform time: 11.06 s\n",
      "INFO 08-16 09:29:57 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 6.359 s\n",
      "INFO 08-16 09:29:59 [monitor.py:34] torch.compile takes 11.06 s in total\n",
      "INFO 08-16 09:30:01 [gpu_worker.py:255] Available KV cache memory: 9.06 GiB\n",
      "INFO 08-16 09:30:01 [kv_cache_utils.py:833] GPU KV cache size: 118,704 tokens\n",
      "INFO 08-16 09:30:01 [kv_cache_utils.py:837] Maximum concurrency for 4,096 tokens per request: 28.98x\n",
      "Capturing CUDA graph shapes: 100%|██████████████| 67/67 [00:03<00:00, 21.83it/s]\n",
      "INFO 08-16 09:30:04 [gpu_model_runner.py:2485] Graph capturing finished in 3 secs, took 0.64 GiB\n",
      "INFO 08-16 09:30:04 [core.py:193] init engine (profile, create kv cache, warmup model) took 25.78 seconds\n",
      "2025-08-16:09:30:05,942 WARNING  [evaluator.py:251] Overwriting default num_fewshot of gsm8k from 5 to 5\n",
      "2025-08-16:09:30:05,943 INFO     [evaluator.py:261] Setting fewshot random generator seed to 1234\n",
      "2025-08-16:09:30:05,944 INFO     [task.py:411] Building contexts for gsm8k on rank 0...\n",
      "100%|████████████████████████████████████████| 250/250 [00:00<00:00, 353.07it/s]\n",
      "2025-08-16:09:30:06,656 INFO     [evaluator.py:438] Running generate_until requests\n",
      "Running generate_until requests:   0%|                  | 0/250 [00:00<?, ?it/s]\n",
      "Adding requests: 100%|██████████████████████| 250/250 [00:00<00:00, 6642.15it/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%| | 0/250 [00:00<?, ?it/s, est. speed input: 0.00 toks/s,\u001b[A\n",
      "Processed prompts:   0%| | 1/250 [00:16<1:10:00, 16.87s/it, est. speed input: 82\u001b[A\n",
      "Processed prompts:   1%| | 2/250 [00:17<30:55,  7.48s/it, est. speed input: 151.\u001b[A\n",
      "Processed prompts:   1%| | 3/250 [00:18<17:32,  4.26s/it, est. speed input: 220.\u001b[A\n",
      "Processed prompts:   2%| | 5/250 [00:19<08:58,  2.20s/it, est. speed input: 345.\u001b[A\n",
      "Processed prompts:   2%| | 6/250 [00:19<06:46,  1.67s/it, est. speed input: 404.\u001b[A\n",
      "Processed prompts:   3%| | 7/250 [00:20<05:08,  1.27s/it, est. speed input: 459.\u001b[A\n",
      "Processed prompts:   3%| | 8/250 [00:20<04:01,  1.00it/s, est. speed input: 536.\u001b[A\n",
      "Processed prompts:   4%| | 10/250 [00:21<02:46,  1.44it/s, est. speed input: 637\u001b[A\n",
      "Processed prompts:   4%| | 11/250 [00:21<02:18,  1.72it/s, est. speed input: 693\u001b[A\n",
      "Processed prompts:   5%| | 12/250 [00:22<02:25,  1.64it/s, est. speed input: 728\u001b[A\n",
      "Processed prompts:   5%| | 13/250 [00:22<02:21,  1.68it/s, est. speed input: 764\u001b[A\n",
      "Processed prompts:   6%| | 14/250 [00:22<02:00,  1.96it/s, est. speed input: 812\u001b[A\n",
      "Processed prompts:   6%| | 15/250 [00:23<01:41,  2.32it/s, est. speed input: 856\u001b[A\n",
      "Processed prompts:   6%| | 16/250 [00:23<01:27,  2.67it/s, est. speed input: 911\u001b[A\n",
      "Processed prompts:   7%| | 17/250 [00:23<01:38,  2.36it/s, est. speed input: 941\u001b[A\n",
      "Processed prompts:   7%| | 18/250 [00:24<01:50,  2.10it/s, est. speed input: 972\u001b[A\n",
      "Processed prompts:   8%| | 19/250 [00:24<01:46,  2.17it/s, est. speed input: 101\u001b[A\n",
      "Processed prompts:   8%| | 20/250 [00:25<01:38,  2.33it/s, est. speed input: 105\u001b[A\n",
      "Processed prompts:   8%| | 21/250 [00:25<01:29,  2.57it/s, est. speed input: 109\u001b[A\n",
      "Processed prompts:   9%| | 23/250 [00:25<01:06,  3.41it/s, est. speed input: 118\u001b[A\n",
      "Processed prompts:  10%| | 25/250 [00:26<01:06,  3.39it/s, est. speed input: 124\u001b[A\n",
      "Processed prompts:  10%| | 26/250 [00:26<01:06,  3.39it/s, est. speed input: 127\u001b[A\n",
      "Processed prompts:  11%| | 28/250 [00:27<01:03,  3.47it/s, est. speed input: 133\u001b[A\n",
      "Processed prompts:  12%| | 29/250 [00:27<01:01,  3.60it/s, est. speed input: 137\u001b[A\n",
      "Processed prompts:  12%| | 30/250 [00:27<00:58,  3.74it/s, est. speed input: 140\u001b[A\n",
      "Processed prompts:  12%| | 31/250 [00:28<01:13,  2.97it/s, est. speed input: 142\u001b[A\n",
      "Processed prompts:  13%|▏| 32/250 [00:28<01:05,  3.35it/s, est. speed input: 145\u001b[A\n",
      "Processed prompts:  13%|▏| 33/250 [00:28<01:11,  3.02it/s, est. speed input: 147\u001b[A\n",
      "Processed prompts:  14%|▏| 34/250 [00:29<01:16,  2.82it/s, est. speed input: 149\u001b[A\n",
      "Processed prompts:  14%|▏| 35/250 [00:29<01:08,  3.15it/s, est. speed input: 153\u001b[A\n",
      "Processed prompts:  14%|▏| 36/250 [00:29<01:10,  3.04it/s, est. speed input: 155\u001b[A\n",
      "Processed prompts:  15%|▏| 37/250 [00:30<01:03,  3.33it/s, est. speed input: 158\u001b[A\n",
      "Processed prompts:  15%|▏| 38/250 [00:30<01:22,  2.58it/s, est. speed input: 159\u001b[A\n",
      "Processed prompts:  16%|▏| 39/250 [00:31<01:23,  2.52it/s, est. speed input: 161\u001b[A\n",
      "Processed prompts:  16%|▏| 40/250 [00:31<01:24,  2.48it/s, est. speed input: 163\u001b[A\n",
      "Processed prompts:  16%|▏| 41/250 [00:31<01:18,  2.66it/s, est. speed input: 166\u001b[A\n",
      "Processed prompts:  17%|▏| 42/250 [00:32<01:20,  2.59it/s, est. speed input: 167\u001b[A\n",
      "Processed prompts:  17%|▏| 43/250 [00:32<01:21,  2.53it/s, est. speed input: 169\u001b[A\n",
      "Processed prompts:  18%|▏| 46/250 [00:33<00:48,  4.18it/s, est. speed input: 179\u001b[A\n",
      "Processed prompts:  19%|▏| 47/250 [00:33<01:08,  2.97it/s, est. speed input: 179\u001b[A\n",
      "Processed prompts:  19%|▏| 48/250 [00:34<01:02,  3.21it/s, est. speed input: 182\u001b[A\n",
      "Processed prompts:  20%|▏| 49/250 [00:34<01:10,  2.84it/s, est. speed input: 184\u001b[A\n",
      "Processed prompts:  20%|▏| 50/250 [00:34<01:04,  3.12it/s, est. speed input: 186\u001b[A\n",
      "Processed prompts:  20%|▏| 51/250 [00:35<01:25,  2.33it/s, est. speed input: 186\u001b[A\n",
      "Processed prompts:  21%|▏| 52/250 [00:35<01:20,  2.46it/s, est. speed input: 188\u001b[A\n",
      "Processed prompts:  21%|▏| 53/250 [00:36<01:45,  1.88it/s, est. speed input: 186\u001b[A\n",
      "Processed prompts:  22%|▏| 54/250 [00:36<01:27,  2.25it/s, est. speed input: 188\u001b[A\n",
      "Processed prompts:  22%|▏| 55/250 [00:37<01:21,  2.39it/s, est. speed input: 190\u001b[A\n",
      "Processed prompts:  23%|▏| 57/250 [00:37<01:05,  2.95it/s, est. speed input: 195\u001b[A\n",
      "Processed prompts:  24%|▏| 59/250 [00:38<00:59,  3.20it/s, est. speed input: 199\u001b[A\n",
      "Processed prompts:  24%|▏| 60/250 [00:38<00:55,  3.42it/s, est. speed input: 201\u001b[A\n",
      "Processed prompts:  24%|▏| 61/250 [00:38<00:54,  3.44it/s, est. speed input: 203\u001b[A\n",
      "Processed prompts:  25%|▎| 63/250 [00:39<01:04,  2.89it/s, est. speed input: 205\u001b[A\n",
      "Processed prompts:  26%|▎| 64/250 [00:39<01:01,  3.01it/s, est. speed input: 207\u001b[A\n",
      "Processed prompts:  26%|▎| 65/250 [00:40<01:02,  2.97it/s, est. speed input: 208\u001b[A\n",
      "Processed prompts:  27%|▎| 68/250 [00:40<00:42,  4.30it/s, est. speed input: 215\u001b[A\n",
      "Processed prompts:  28%|▎| 71/250 [00:41<00:45,  3.93it/s, est. speed input: 221\u001b[A\n",
      "Processed prompts:  30%|▎| 74/250 [00:42<00:45,  3.86it/s, est. speed input: 227\u001b[A\n",
      "Processed prompts:  31%|▎| 77/250 [00:43<00:42,  4.09it/s, est. speed input: 233\u001b[A\n",
      "Processed prompts:  32%|▎| 80/250 [00:43<00:41,  4.14it/s, est. speed input: 238\u001b[A\n",
      "Processed prompts:  34%|▎| 85/250 [00:44<00:36,  4.56it/s, est. speed input: 247\u001b[A\n",
      "Processed prompts:  35%|▎| 87/250 [00:45<00:35,  4.53it/s, est. speed input: 250\u001b[A\n",
      "Processed prompts:  36%|▎| 90/250 [00:45<00:33,  4.73it/s, est. speed input: 255\u001b[A\n",
      "Processed prompts:  37%|▎| 92/250 [00:46<00:33,  4.67it/s, est. speed input: 258\u001b[A\n",
      "Processed prompts:  38%|▍| 95/250 [00:46<00:31,  4.86it/s, est. speed input: 263\u001b[A\n",
      "Processed prompts:  38%|▍| 96/250 [00:47<00:34,  4.51it/s, est. speed input: 263\u001b[A\n",
      "Processed prompts:  40%|▍| 99/250 [00:47<00:31,  4.80it/s, est. speed input: 268\u001b[A\n",
      "Processed prompts:  40%|▍| 100/250 [00:47<00:31,  4.76it/s, est. speed input: 26\u001b[A\n",
      "Processed prompts:  40%|▍| 101/250 [00:48<00:37,  3.97it/s, est. speed input: 26\u001b[A\n",
      "Processed prompts:  41%|▍| 102/250 [00:48<00:42,  3.46it/s, est. speed input: 26\u001b[A\n",
      "Processed prompts:  41%|▍| 103/250 [00:48<00:41,  3.50it/s, est. speed input: 26\u001b[A\n",
      "Processed prompts:  42%|▍| 104/250 [00:49<00:48,  3.03it/s, est. speed input: 26\u001b[A\n",
      "Processed prompts:  42%|▍| 105/250 [00:49<00:46,  3.14it/s, est. speed input: 27\u001b[A\n",
      "Processed prompts:  42%|▍| 106/250 [00:50<01:11,  2.01it/s, est. speed input: 26\u001b[A\n",
      "Processed prompts:  43%|▍| 107/250 [00:51<01:06,  2.16it/s, est. speed input: 26\u001b[A\n",
      "Processed prompts:  43%|▍| 108/250 [00:51<01:03,  2.23it/s, est. speed input: 26\u001b[A\n",
      "Processed prompts:  44%|▍| 109/250 [00:51<00:58,  2.39it/s, est. speed input: 26\u001b[A\n",
      "Processed prompts:  44%|▍| 110/250 [00:52<00:52,  2.64it/s, est. speed input: 26\u001b[A\n",
      "Processed prompts:  44%|▍| 111/250 [00:52<00:59,  2.35it/s, est. speed input: 26\u001b[A\n",
      "Processed prompts:  45%|▍| 112/250 [00:53<00:55,  2.51it/s, est. speed input: 26\u001b[A\n",
      "Processed prompts:  46%|▍| 114/250 [00:53<00:41,  3.29it/s, est. speed input: 27\u001b[A\n",
      "Processed prompts:  46%|▍| 116/250 [00:54<00:44,  3.02it/s, est. speed input: 27\u001b[A\n",
      "Processed prompts:  47%|▍| 117/250 [00:54<00:43,  3.07it/s, est. speed input: 27\u001b[A\n",
      "Processed prompts:  47%|▍| 118/250 [00:54<00:43,  3.04it/s, est. speed input: 27\u001b[A\n",
      "Processed prompts:  48%|▍| 119/250 [00:55<00:56,  2.32it/s, est. speed input: 26\u001b[A\n",
      "Processed prompts:  48%|▍| 120/250 [00:55<00:48,  2.66it/s, est. speed input: 27\u001b[A\n",
      "Processed prompts:  48%|▍| 121/250 [00:56<00:45,  2.86it/s, est. speed input: 27\u001b[A\n",
      "Processed prompts:  49%|▍| 123/250 [00:56<00:38,  3.31it/s, est. speed input: 27\u001b[A\n",
      "Processed prompts:  50%|▍| 124/250 [00:56<00:39,  3.17it/s, est. speed input: 27\u001b[A\n",
      "Processed prompts:  50%|▌| 125/250 [00:57<00:38,  3.28it/s, est. speed input: 27\u001b[A\n",
      "Processed prompts:  51%|▌| 127/250 [00:57<00:27,  4.52it/s, est. speed input: 27\u001b[A\n",
      "Processed prompts:  52%|▌| 129/250 [00:57<00:26,  4.61it/s, est. speed input: 27\u001b[A\n",
      "Processed prompts:  52%|▌| 130/250 [00:58<00:28,  4.24it/s, est. speed input: 27\u001b[A\n",
      "Processed prompts:  52%|▌| 131/250 [00:58<00:31,  3.75it/s, est. speed input: 27\u001b[A\n",
      "Processed prompts:  53%|▌| 132/250 [00:58<00:33,  3.51it/s, est. speed input: 27\u001b[A\n",
      "Processed prompts:  53%|▌| 133/250 [00:58<00:30,  3.79it/s, est. speed input: 27\u001b[A\n",
      "Processed prompts:  54%|▌| 134/250 [00:59<00:33,  3.51it/s, est. speed input: 27\u001b[A\n",
      "Processed prompts:  54%|▌| 135/250 [00:59<00:44,  2.57it/s, est. speed input: 27\u001b[A\n",
      "Processed prompts:  54%|▌| 136/250 [01:00<00:39,  2.85it/s, est. speed input: 27\u001b[A\n",
      "Processed prompts:  55%|▌| 137/250 [01:00<00:37,  3.05it/s, est. speed input: 27\u001b[A\n",
      "Processed prompts:  55%|▌| 138/250 [01:00<00:34,  3.22it/s, est. speed input: 28\u001b[A\n",
      "Processed prompts:  56%|▌| 139/250 [01:01<00:33,  3.36it/s, est. speed input: 28\u001b[A\n",
      "Processed prompts:  56%|▌| 140/250 [01:01<00:32,  3.37it/s, est. speed input: 28\u001b[A\n",
      "Processed prompts:  56%|▌| 141/250 [01:01<00:29,  3.73it/s, est. speed input: 28\u001b[A\n",
      "Processed prompts:  57%|▌| 142/250 [01:01<00:28,  3.74it/s, est. speed input: 28\u001b[A\n",
      "Processed prompts:  58%|▌| 144/250 [01:02<00:27,  3.92it/s, est. speed input: 28\u001b[A\n",
      "Processed prompts:  58%|▌| 146/250 [01:02<00:18,  5.56it/s, est. speed input: 28\u001b[A\n",
      "Processed prompts:  60%|▌| 149/250 [01:02<00:13,  7.38it/s, est. speed input: 29\u001b[A\n",
      "Processed prompts:  61%|▌| 152/250 [01:02<00:09, 10.17it/s, est. speed input: 29\u001b[A\n",
      "Processed prompts:  62%|▌| 155/250 [01:02<00:07, 12.98it/s, est. speed input: 30\u001b[A\n",
      "Processed prompts:  63%|▋| 158/250 [01:03<00:05, 15.69it/s, est. speed input: 30\u001b[A\n",
      "Processed prompts:  64%|▋| 161/250 [01:03<00:05, 14.94it/s, est. speed input: 30\u001b[A\n",
      "Processed prompts:  66%|▋| 164/250 [01:03<00:06, 13.44it/s, est. speed input: 31\u001b[A\n",
      "Processed prompts:  66%|▋| 166/250 [01:03<00:06, 13.20it/s, est. speed input: 31\u001b[A\n",
      "Processed prompts:  67%|▋| 168/250 [01:03<00:06, 13.06it/s, est. speed input: 31\u001b[A\n",
      "Processed prompts:  68%|▋| 170/250 [01:04<00:06, 11.96it/s, est. speed input: 31\u001b[A\n",
      "Processed prompts:  69%|▋| 173/250 [01:04<00:05, 12.97it/s, est. speed input: 32\u001b[A\n",
      "Processed prompts:  71%|▋| 177/250 [01:04<00:04, 15.33it/s, est. speed input: 32\u001b[A\n",
      "Processed prompts:  72%|▋| 180/250 [01:04<00:05, 13.68it/s, est. speed input: 33\u001b[A\n",
      "Processed prompts:  73%|▋| 182/250 [01:05<00:08,  7.60it/s, est. speed input: 33\u001b[A\n",
      "Processed prompts:  74%|▋| 184/250 [01:05<00:08,  7.92it/s, est. speed input: 33\u001b[A\n",
      "Processed prompts:  76%|▊| 190/250 [01:05<00:04, 12.70it/s, est. speed input: 34\u001b[A\n",
      "Processed prompts:  77%|▊| 192/250 [01:05<00:04, 13.40it/s, est. speed input: 34\u001b[A\n",
      "Processed prompts:  78%|▊| 194/250 [01:06<00:04, 13.37it/s, est. speed input: 34\u001b[A\n",
      "Processed prompts:  78%|▊| 196/250 [01:06<00:04, 11.41it/s, est. speed input: 34\u001b[A\n",
      "Processed prompts:  80%|▊| 200/250 [01:06<00:03, 15.88it/s, est. speed input: 35\u001b[A\n",
      "Processed prompts:  81%|▊| 203/250 [01:06<00:02, 17.46it/s, est. speed input: 35\u001b[A\n",
      "Processed prompts:  82%|▊| 206/250 [01:06<00:03, 12.32it/s, est. speed input: 35\u001b[A\n",
      "Processed prompts:  84%|▊| 209/250 [01:07<00:03, 12.83it/s, est. speed input: 36\u001b[A\n",
      "Processed prompts:  85%|▊| 213/250 [01:07<00:02, 16.63it/s, est. speed input: 36\u001b[A\n",
      "Processed prompts:  86%|▊| 216/250 [01:07<00:02, 15.68it/s, est. speed input: 37\u001b[A\n",
      "Processed prompts:  89%|▉| 222/250 [01:07<00:01, 22.45it/s, est. speed input: 37\u001b[A\n",
      "Processed prompts:  91%|▉| 228/250 [01:07<00:00, 29.49it/s, est. speed input: 38\u001b[A\n",
      "Processed prompts:  94%|▉| 234/250 [01:07<00:00, 33.87it/s, est. speed input: 39\u001b[A\n",
      "Processed prompts:  95%|▉| 238/250 [01:08<00:00, 28.52it/s, est. speed input: 39\u001b[A\n",
      "Processed prompts:  97%|▉| 242/250 [01:08<00:00, 15.65it/s, est. speed input: 40\u001b[A\n",
      "Processed prompts:  98%|▉| 245/250 [01:08<00:00, 14.86it/s, est. speed input: 40\u001b[A\n",
      "Processed prompts: 100%|▉| 249/250 [01:08<00:00, 18.23it/s, est. speed input: 40\u001b[A\n",
      "Processed prompts: 100%|█| 250/250 [01:09<00:00,  3.62it/s, est. speed input: 40\u001b[A\n",
      "Running generate_until requests: 100%|████████| 250/250 [01:09<00:00,  3.61it/s]\n",
      "fatal: not a git repository (or any parent up to mount point /opt/app-root)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
      "2025-08-16:09:31:17,192 INFO     [evaluation_tracker.py:240] Output path not provided, skipping saving results aggregated\n",
      "vllm (pretrained=/opt/app-root/src/granite-3.2-2b-instruct-W4A16,add_bos_token=true,max_model_len=4096,gpu_memory_utilization=0.5,trust_remote_code=True), gen_kwargs: (None), limit: 250.0, num_fewshot: 5, batch_size: auto\n",
      "|Tasks|Version|     Filter     |n-shot|  Metric   |   |Value|   |Stderr|\n",
      "|-----|------:|----------------|-----:|-----------|---|----:|---|-----:|\n",
      "|gsm8k|      3|flexible-extract|     5|exact_match|↑  | 0.56|±  |0.0315|\n",
      "|     |       |strict-match    |     5|exact_match|↑  | 0.42|±  |0.0313|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "MODEL_ID = current_dir + \"/granite-3.2-2b-instruct-W4A16\"\n",
    "\n",
    "!lm_eval --model vllm \\\n",
    "  --model_args \"pretrained=$MODEL_ID,add_bos_token=true,max_model_len=4096,gpu_memory_utilization=0.5\" \\\n",
    "  --trust_remote_code \\\n",
    "  --tasks gsm8k \\\n",
    "  --num_fewshot 5 \\\n",
    "  --limit 250 \\\n",
    "  --batch_size 'auto'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b570baf-46e1-46e9-b970-c3f156814a69",
   "metadata": {},
   "source": [
    "With powerful GPU(s), you could also run the vLLM based evals with the following - using higher GPU memory utilization and chunked prefill. \n",
    "```bash\n",
    "!lm_eval \\\n",
    "  --model vllm \\\n",
    "  --model_args pretrained=$SAVE_DIR,dtype=auto,add_bos_token=True,max_model_len=4096,tensor_parallel_size=1,gpu_memory_utilization=0.8,enable_chunked_prefill=True \\\n",
    "  --trust_remote_code \\\n",
    "  --tasks openllm \\\n",
    "  --write_out \\\n",
    "  --batch_size auto \\\n",
    "  --output_path output_dir \\\n",
    "  --show_config\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1a1582",
   "metadata": {},
   "source": [
    "### Upload the optimized model to MinIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ceb1e422-0ea3-41df-97cd-36cbcf4e5520",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting upload of quantizied model\n",
      "Uploading predictions to bucket models to S3 storage at http://minio-service.minio.svc.cluster.local:9000\n",
      "Uploaded /opt/app-root/src/granite-3.2-2b-instruct-W4A16/added_tokens.json\n",
      "Uploaded /opt/app-root/src/granite-3.2-2b-instruct-W4A16/model.safetensors\n",
      "Uploaded /opt/app-root/src/granite-3.2-2b-instruct-W4A16/special_tokens_map.json\n",
      "Uploaded /opt/app-root/src/granite-3.2-2b-instruct-W4A16/generation_config.json\n",
      "Uploaded /opt/app-root/src/granite-3.2-2b-instruct-W4A16/tokenizer_config.json\n",
      "Uploaded /opt/app-root/src/granite-3.2-2b-instruct-W4A16/vocab.json\n",
      "Uploaded /opt/app-root/src/granite-3.2-2b-instruct-W4A16/merges.txt\n",
      "Uploaded /opt/app-root/src/granite-3.2-2b-instruct-W4A16/recipe.yaml\n",
      "Uploaded /opt/app-root/src/granite-3.2-2b-instruct-W4A16/chat_template.jinja\n",
      "Uploaded /opt/app-root/src/granite-3.2-2b-instruct-W4A16/tokenizer.json\n",
      "Uploaded /opt/app-root/src/granite-3.2-2b-instruct-W4A16/config.json\n",
      "Finished uploading of quantizied model\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from boto3 import client\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "OPTIMIZED_MODEL_DIR = current_dir + \"/granite-3.2-2b-instruct-W4A16\"\n",
    "S3_PATH = \"granite-int4-notebook\"\n",
    "\n",
    "print('Starting upload of quantizied model')\n",
    "s3_endpoint_url = os.environ[\"AWS_S3_ENDPOINT\"]\n",
    "s3_access_key = os.environ[\"AWS_ACCESS_KEY_ID\"]\n",
    "s3_secret_key = os.environ[\"AWS_SECRET_ACCESS_KEY\"]\n",
    "s3_bucket_name = os.environ[\"AWS_S3_BUCKET\"]\n",
    "\n",
    "print(f'Uploading predictions to bucket {s3_bucket_name} '\n",
    "        f'to S3 storage at {s3_endpoint_url}')\n",
    "\n",
    "s3_client = client(\n",
    "    's3', endpoint_url=s3_endpoint_url, aws_access_key_id=s3_access_key,\n",
    "    aws_secret_access_key=s3_secret_key, verify=False\n",
    ")\n",
    "\n",
    "# Walk through the local folder and upload files\n",
    "for root, dirs, files in os.walk(OPTIMIZED_MODEL_DIR):\n",
    "    for file in files:\n",
    "        local_file_path = os.path.join(root, file)\n",
    "        s3_file_path = os.path.join(S3_PATH, local_file_path[len(OPTIMIZED_MODEL_DIR)+1:])\n",
    "        s3_client.upload_file(local_file_path, s3_bucket_name, s3_file_path)\n",
    "        print(f'Uploaded {local_file_path}')\n",
    "\n",
    "print('Finished uploading of quantizied model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2aa2928-327f-4e81-90be-82623d3bd8a7",
   "metadata": {},
   "source": [
    "### Bonus labs\n",
    "- Experiment with different quantization scheme & method to further improve its accuracy\n",
    "- Prepare a new dataset tailored to a specific use case by collecting and performing data mixing for calibration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
