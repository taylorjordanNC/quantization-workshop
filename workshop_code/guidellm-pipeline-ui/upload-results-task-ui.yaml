apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: upload-guidellm-benchmark-results-ui
spec:
  description: Upload guidellm benchmark results to s3 bucket
  params:
    - default: 'http://minio-service.minio.svc.cluster.local:9000'
      description: s3 API endpoint
      name: minio-api-route
      type: string
    - default: minio
      description: s3 username
      name: user
      type: string
    - default: minio123
      description: s3 password
      name: password
      type: string
  steps:
    - computeResources: {}
      env:
        - name: REQUESTS_CA_BUNDLE
          value: /etc/ssl/certs/ca-bundle.crt
        - name: SSL_CERT_FILE
          value: /etc/ssl/certs/ca-bundle.crt
        - name: PARAM_S3_ENDPOINT_URL
          value: $(params.minio-api-route)
        - name: PARAM_S3_USERNAME
          value: 'minio'
        - name: PARAM_S3_PASSWORD
          value: 'minio123'
      image: registry.access.redhat.com/ubi9/python-311
      name: upload-benchmark
      script: |
        #!/usr/bin/env python3

        import os

        # Install dependencies quietly
        os.system('pip install -q boto3')

        import boto3
        import glob
        import sys
        from botocore.client import Config

        # --- Get credentials and endpoint from environment variables ---
        S3_ENDPOINT_URL = 'http://minio-service.minio.svc.cluster.local:9000'
        S3_USERNAME = 'minio'
        S3_PASSWORD = 'minio123'

        def upload_files_to_s3(bucket_name, search_directory, file_pattern):
            """
            Finds all files matching a pattern in a directory and uploads them to an S3 bucket.
            It explicitly skips directories.
            """
            try:
                s3_client = boto3.client(
                    's3',
                    endpoint_url=S3_ENDPOINT_URL,
                    aws_access_key_id=S3_USERNAME,
                    aws_secret_access_key=S3_PASSWORD,
                    config=Config(s3={'addressing_style': 'path'})
                )
            except Exception as e:
                print(f"Failed to create S3 client: {e}")
                return

            search_path = os.path.join(search_directory, file_pattern)
            print(f"Searching for items with pattern: {search_path}")
            found_items = glob.glob(search_path)

            if not found_items:
                print("No items found matching the pattern.")
                return

            print(f"Found {len(found_items)} item(s). Starting upload process...")

            for item_path in found_items:
                if os.path.isfile(item_path):
                    try:
                        s3_object_key = os.path.basename(item_path)
                        print(f"  Uploading '{item_path}' to bucket '{bucket_name}' as '{s3_object_key}'...")
                        s3_client.upload_file(item_path, bucket_name, s3_object_key)
                        print(f"Upload successful for: {item_path}")
                    except Exception as e:
                        print(f"Error uploading file {item_path}: {e}")
                else:
                    print(f" Skipping '{item_path}' because it is a directory.")

        if __name__ == '__main__':
            S3_BUCKET = 'guidellm-benchmark'
            LOCAL_DIRECTORY = '/workspace/shared-workspace/'

            try:
                # Upload timestamped files (tar.gz archives, etc.)
                with open("/workspace/shared-workspace/timestamp.txt", "r") as f:
                    timestamp = f.read().strip()
                print(f"Using timestamp '{timestamp}' to find timestamped files.")
                WILDCARD_PATTERN = f"*{timestamp}*"
                upload_files_to_s3(S3_BUCKET, LOCAL_DIRECTORY, WILDCARD_PATTERN)
                
                # Also upload HTML/specific benchmark files (without timestamp)
                print("Uploading HTML benchmark files...")
                html_patterns = ["*.html", "*.json", "*.yaml"]
                for pattern in html_patterns:
                    print(f"Searching for files with pattern: {pattern}")
                    upload_files_to_s3(S3_BUCKET, LOCAL_DIRECTORY, pattern)
                    
            except FileNotFoundError:
                print("Error: timestamp.txt not found. Cannot determine timestamped files to upload.")
                # Still try to upload HTML files even if timestamp is missing
                print("Attempting to upload HTML files anyway...")
                html_patterns = ["*.html", "*.json", "*.yaml"] 
                for pattern in html_patterns:
                    upload_files_to_s3(S3_BUCKET, LOCAL_DIRECTORY, pattern)
            except Exception as e:
                print(f"An unexpected error occurred: {e}")
      workingDir: $(workspaces.shared-workspace.path)
  workspaces:
    - description: Shared workspace for storing benchmark results
      name: shared-workspace