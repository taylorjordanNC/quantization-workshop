apiVersion: apps/v1
kind: Deployment
metadata:
  name: guidellm-wb
  namespace: rhaiis-evals
spec:
  replicas: 1
  selector:
    matchLabels: { app: guidellm-wb }
  template:
    metadata:
      labels: { app: guidellm-wb }
    spec:
      # Optional if you ever add ARM nodes:
      # nodeSelector:
      #   kubernetes.io/arch: amd64
      containers:
        - name: app
          image: quay.io/rh-aiservices-bu/guidellm-wb:v1
          # Run via a shell to avoid exec-bit issues on /app/entrypoint.sh
          command: ["/bin/bash","-lc"]
          args: ["bash /app/entrypoint.sh"]
          ports:
            - containerPort: 8501
              name: http
          readinessProbe:
            httpGet:
              path: /
              port: http
            initialDelaySeconds: 5
            periodSeconds: 5
          livenessProbe:
            httpGet:
              path: /
              port: http
            initialDelaySeconds: 20
            periodSeconds: 10
          resources:
            requests:
              cpu: "250m"
              memory: "512Mi"
